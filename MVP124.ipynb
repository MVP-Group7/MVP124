{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MVP-Group7/MVP124/blob/textual-inversion-test/MVP124.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. SSH Key Setup"
      ],
      "metadata": {
        "id": "haUJh9ZhJb0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p /root/.ssh\n",
        "with open(\"/root/.ssh/id_rsa\", mode=\"w\") as fp:\n",
        "    fp.write(\"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAACFwAAAAdzc2gtcn\n",
        "NhAAAAAwEAAQAAAgEAuQQtwBlx+GQt4YH99RKAgImb7vfY0+2djVboYst2efMdmbxvAQ3t\n",
        "gFrpWYifIA98UbZyGQcmXr8Rh2wQjwd4qY1fyE1qsrHQ0t/a8kPXK7jCpvIarC8Z8Ck4Ho\n",
        "0HGdLBHwDA+K6vK4MTzQl/8fmKPEnGYHDPXmvqWyHFMW66SXdkyxkDT0od/4RexxH6R481\n",
        "KGejaSqsGYWoga+ALX7h8NDh1gaCTIZvifo/IPixfI09SxH2AH9qTQST8ruvbPeslQ0eMS\n",
        "XAp2IuQICE8nMZtA5Ft6smPkwulejgv4c5qYA4DOs09gHHJulciF0tv5Od+tCyjlj8g7i3\n",
        "8qlr/vdxX6ChILH3+bbemm+HLUyzrd4sVbmWD8NT2MOzMH/czYPnkjulw8qWL8aOGn6XpM\n",
        "yvxQ0/aQyls2uAt7zBdDLNBYZ11ZpSLs5qdOl9EbBIA+mBQeoLpDe0QuTfpiloCFbAFly5\n",
        "C1q/Z3vs60DC3iqh1JgWcs6y4GKOeLHq1nu6l6Rns1UMCjXqaWxuRMotXD3eaPj+SsWmOu\n",
        "1WoZ8AdHJcfHXWTpMQaUtGgAY7gyXBO6Slg0m+hM5aObjsSKsdPWVE1D0i91oes2iSfbUs\n",
        "RZxAnH3GvOssrJ3xg0jKkyz0syrUOt3CS7nQj+h4b49Vk67zvIvGZeN1wo1Qfqab31Ogsx\n",
        "MAAAdIsAgiFLAIIhQAAAAHc3NoLXJzYQAAAgEAuQQtwBlx+GQt4YH99RKAgImb7vfY0+2d\n",
        "jVboYst2efMdmbxvAQ3tgFrpWYifIA98UbZyGQcmXr8Rh2wQjwd4qY1fyE1qsrHQ0t/a8k\n",
        "PXK7jCpvIarC8Z8Ck4Ho0HGdLBHwDA+K6vK4MTzQl/8fmKPEnGYHDPXmvqWyHFMW66SXdk\n",
        "yxkDT0od/4RexxH6R481KGejaSqsGYWoga+ALX7h8NDh1gaCTIZvifo/IPixfI09SxH2AH\n",
        "9qTQST8ruvbPeslQ0eMSXAp2IuQICE8nMZtA5Ft6smPkwulejgv4c5qYA4DOs09gHHJulc\n",
        "iF0tv5Od+tCyjlj8g7i38qlr/vdxX6ChILH3+bbemm+HLUyzrd4sVbmWD8NT2MOzMH/czY\n",
        "Pnkjulw8qWL8aOGn6XpMyvxQ0/aQyls2uAt7zBdDLNBYZ11ZpSLs5qdOl9EbBIA+mBQeoL\n",
        "pDe0QuTfpiloCFbAFly5C1q/Z3vs60DC3iqh1JgWcs6y4GKOeLHq1nu6l6Rns1UMCjXqaW\n",
        "xuRMotXD3eaPj+SsWmOu1WoZ8AdHJcfHXWTpMQaUtGgAY7gyXBO6Slg0m+hM5aObjsSKsd\n",
        "PWVE1D0i91oes2iSfbUsRZxAnH3GvOssrJ3xg0jKkyz0syrUOt3CS7nQj+h4b49Vk67zvI\n",
        "vGZeN1wo1Qfqab31OgsxMAAAADAQABAAACAExjyEv/dYocOsFYPbXZPMtVhdeF57Wg7yMz\n",
        "VeGspi81zOvz3FUwHfaYEq7P9Pt0yVynmrZwuEv4UdF7Md8MM6q1321BYaOEPXdDzA+pKQ\n",
        "c5Us1BOvgKvoflTPF4Qw1LckdNtV84KMUrapqGqJgM8yFvSIP7L/OJVQrph5SgZjP9ItWk\n",
        "bzRmorokOkmxR4gSPd1/5P2AC+zBvdBF2QNv1vPqGsSWjWfxPc5XT4dah1Worzz2nn6YHR\n",
        "jNohRfn8+69zvXXbbnIoM5y2UAa2P7WAp6thhehvzD0Zw9ucX6nDk64mmbF5PXKhYL1hPL\n",
        "fR8TYO/1CTQy05fDRdfgUeHE4r7ntdW9c2vaPwWoP2JLlNvE0a2unHRDgAHDcVrPTAVTn6\n",
        "pUwRPuJIDlDQjTX5OFVONn3l+0AmndWEchPQh/IIAj1WwI9sKaGpFkRRt13Fbs4s1JsCmU\n",
        "IaY8cGi120GXdLakVBMX8WysSQBKBvw7BtMNOve664wH1wuYIKHYGbAL1izMGqlsOFzizn\n",
        "S4KsqCYEqM444DQWdqDMD27AXU5LyZ23JbeCyrGUtg4RSyQhw9F3ZpGY+AOL3AfcwWwQN6\n",
        "oFXdpy9uzDY7EL+qhuBh5aofbFNvqb09TH4QnVRxyaIlD36f0GOb76XjlfbNMK9hVicGIe\n",
        "ibcnBXghpEEyRMKXNJAAABAHz4WwyiiOjVw2MN5R1Q6eUtK2EBrVYc3/q9UJU5jE9zvrOM\n",
        "aJspipki11R+08SdSbyY8cmdfUIuqqWf79A5Cjytbye2Y65HZD/R/W3wkN2EpCMcqzcQ3Q\n",
        "Fx2Xdt3SnY2ZARc6dgGR0YKND4ZRc3UHlusGIR/QAyGl4KySq3VdrnT9ih8dGGO5cnz2hh\n",
        "tYtGsQ0+FjOeBnf6Mk6UBhAziPlbWUuyjTc0bD5kYbc9J3S+c4qCwNFmoKbbnJ750jssv6\n",
        "PM/iWUMOQJeHO9+i6ZmdplS8A+GrKQZ3ox/axKc98kQHR5Y1330b6Wjfw9S26aH8tPorVz\n",
        "Ny68X7htJ2UPeKIAAAEBAOvDSEd5iePYS0iCXzGu1c/0WHTYDleWpXHEO/7rg0P7CfewIB\n",
        "shBhPx6GoaWG4PMMqziUfsb2nqycum8i64RUh2h3JBW/IUQdkksuaElDY3YLg+tn6mtC17\n",
        "lp3sb64IyqeByXZhtVTCS0yo/TtLQWbeG4L5+J+NIEaWoHWR1vhJw+vh+ugUz8csd/GSjU\n",
        "zrsbrdfs73Wkk8DxhR+Aom6ibrxkFVR2SPmFdrELXWK2oAKcuzTnTzrXn7lR1oPrKXGbur\n",
        "hzbAxVhUaGTtcoPuVWhTaZRKHpIlyq14SuVYCoTnkIZg3u4f7ZfOsPYqrzMBNKcd7Pih4e\n",
        "T0XEHnFPHgL+UAAAEBAMjlx1r+3Un8bG5aVcrzXdWcR1MycN6efPpHJXd248EyTmFZsyuu\n",
        "9WcOikUTi+GDf8UnqOk7WlrbQ2MOtAsNv1cZ2BdoPHao6R6lLPfDhgQpgzmjpgkZRDicJJ\n",
        "ojTceLvyhgH8RJ+Ug3WBudxPMhpoUqZ9WXjnKzgdi0BVnJprT4XD7LYWfyv3fezByaq2U2\n",
        "v8i6WyUwQdZKswlYTOLfaq5H16iMO+DF//xtJoBkLQt3uY1VLkC5eNlYSq9Kupo70NVWDM\n",
        "8ttTrQ+9eksw2rB4GfAeafEmSY83OyIRUebu4/DZd8o8Tzkidgox9nAEeiL62Mrc8ux20a\n",
        "R6EjU72Nd5cAAAARcm9vdEA5MmY0ODIwOTA3NjgBAg==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\")\n",
        "! ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
        "! chmod go-rwx /root/.ssh/id_rsa\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mte4oCt1KcZp",
        "outputId": "01747346-4a00-45c9-f86a-8f3b79762243"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-9e2e2a76e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Code and Dependencies Setup\n"
      ],
      "metadata": {
        "id": "aCZ7NKEEJd-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/threestudio-project/threestudio.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmjX0G4rDHq0",
        "outputId": "e8319525-00ff-42a2-e2a8-0281c7997b4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'threestudio'...\n",
            "remote: Enumerating objects: 7229, done.\u001b[K\n",
            "remote: Counting objects: 100% (225/225), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 7229 (delta 130), reused 158 (delta 85), pack-reused 7004 (from 1)\u001b[K\n",
            "Receiving objects: 100% (7229/7229), 21.85 MiB | 11.16 MiB/s, done.\n",
            "Resolving deltas: 100% (5402/5402), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CTiYAtGC2B5",
        "outputId": "759cbf12-738e-45c1-f471-d7a4a7f9b2a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/threestudio\n"
          ]
        }
      ],
      "source": [
        "%cd threestudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd custom\n",
        "! git clone git@github.com:MVP-Group7/MVP124.git"
      ],
      "metadata": {
        "id": "I1wKO4ZGTWSD",
        "outputId": "e1e26c0e-c1ef-4337-fdc5-02e45fdddf67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/threestudio/custom\n",
            "Cloning into 'MVP124'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 159 (delta 60), reused 105 (delta 22), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (159/159), 4.47 MiB | 2.88 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MVP124"
      ],
      "metadata": {
        "id": "BSOJc2Kl9UG0",
        "outputId": "50e8d519-112b-4716-9f7e-7d0820c61b51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/threestudio/custom/MVP124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xEtZ42e09K2J",
        "outputId": "d1c885fd-5c7e-44ab-ae78-5901af170662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/NVlabs/nvdiffrast/ (from -r requirements.txt (line 33))\n",
            "  Cloning https://github.com/NVlabs/nvdiffrast/ to /tmp/pip-req-build-3nr992hc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NVlabs/nvdiffrast/ /tmp/pip-req-build-3nr992hc\n",
            "  Resolved https://github.com/NVlabs/nvdiffrast/ to commit 729261dc64c4241ea36efda84fbf532cc8b425b8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/openai/CLIP.git (from -r requirements.txt (line 43))\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-gh_unrpk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-gh_unrpk\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/ashawkey/cubvh (from -r requirements.txt (line 53))\n",
            "  Cloning https://github.com/ashawkey/cubvh to /tmp/pip-req-build-lfgiikr_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ashawkey/cubvh /tmp/pip-req-build-lfgiikr_\n",
            "  Resolved https://github.com/ashawkey/cubvh to commit 7f935a0fd3d8168c45b671f3e9cff9b206fdf32b\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/openai/shap-e (from -r requirements.txt (line 62))\n",
            "  Cloning https://github.com/openai/shap-e to /tmp/pip-req-build-f5qcpfh9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/shap-e /tmp/pip-req-build-f5qcpfh9\n",
            "  Resolved https://github.com/openai/shap-e to commit 50131012ee11c9d2617f3886c10f000d3c7a3b43\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (13.9.4)\n",
            "Collecting ninja (from -r requirements.txt (line 3))\n",
            "  Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.36.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.2.2)\n",
            "Collecting torch-ema (from -r requirements.txt (line 13))\n",
            "  Downloading torch_ema-0.3-py3-none-any.whl.metadata (415 bytes)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.8.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.17.1)\n",
            "Collecting tensorboardX (from -r requirements.txt (line 16))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting dearpygui (from -r requirements.txt (line 19))\n",
            "  Downloading dearpygui-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (0.26.2)\n",
            "Collecting diffusers==0.20.2 (from -r requirements.txt (line 26))\n",
            "  Downloading diffusers-0.20.2.tar.gz (989 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.1/989.1 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (4.46.2)\n",
            "Collecting xatlas (from -r requirements.txt (line 31))\n",
            "  Downloading xatlas-0.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting PyMCubes (from -r requirements.txt (line 32))\n",
            "  Downloading PyMCubes-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (868 bytes)\n",
            "Collecting rembg (from -r requirements.txt (line 36))\n",
            "  Downloading rembg-2.0.60-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting carvekit-colab (from -r requirements.txt (line 38))\n",
            "  Downloading carvekit_colab-4.1.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting omegaconf (from -r requirements.txt (line 39))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytorch-lightning (from -r requirements.txt (line 40))\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting taming-transformers-rom1504 (from -r requirements.txt (line 41))\n",
            "  Downloading taming_transformers_rom1504-0.0.6-py3-none-any.whl.metadata (406 bytes)\n",
            "Collecting kornia (from -r requirements.txt (line 42))\n",
            "  Downloading kornia-0.7.4-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 46)) (5.2.0)\n",
            "Collecting trimesh (from -r requirements.txt (line 49))\n",
            "  Downloading trimesh-4.5.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting pymeshlab (from -r requirements.txt (line 50))\n",
            "  Downloading pymeshlab-2023.12.post2-cp310-cp310-manylinux_2_31_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting timm==0.6.7 (from -r requirements.txt (line 56))\n",
            "  Downloading timm-0.6.7-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 57)) (1.13)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 58)) (0.18.7)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 59)) (2.5.0)\n",
            "Collecting jupyterlab (from -r requirements.txt (line 65))\n",
            "  Downloading jupyterlab-4.3.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting debugpy-run (from -r requirements.txt (line 68))\n",
            "  Downloading debugpy_run-1.12-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 71)) (0.2.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 74)) (5.9.5)\n",
            "Collecting lpips (from -r requirements.txt (line 77))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pytorch_msssim (from -r requirements.txt (line 78))\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting ipdb (from -r requirements.txt (line 79))\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2->-r requirements.txt (line 26)) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2->-r requirements.txt (line 26)) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2->-r requirements.txt (line 26)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2->-r requirements.txt (line 26)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2->-r requirements.txt (line 26)) (0.4.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2->-r requirements.txt (line 26)) (11.0.0)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.6.7->-r requirements.txt (line 56)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.6.7->-r requirements.txt (line 56)) (0.20.1+cu121)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg->-r requirements.txt (line 10)) (75.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 11)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 11)) (2024.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 15)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 15)) (4.25.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 15)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 25)) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 25)) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 28)) (0.20.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from rembg->-r requirements.txt (line 36)) (4.23.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from rembg->-r requirements.txt (line 36)) (4.10.0.84)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from rembg->-r requirements.txt (line 36)) (1.8.2)\n",
            "Collecting pymatting (from rembg->-r requirements.txt (line 36))\n",
            "  Downloading PyMatting-1.1.13-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from rembg->-r requirements.txt (line 36)) (0.24.0)\n",
            "Collecting loguru (from carvekit-colab->-r requirements.txt (line 38))\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvicorn (from carvekit-colab->-r requirements.txt (line 38))\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastapi (from carvekit-colab->-r requirements.txt (line 38))\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from carvekit-colab->-r requirements.txt (line 38)) (2.9.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from carvekit-colab->-r requirements.txt (line 38)) (8.1.7)\n",
            "Collecting aiofiles (from carvekit-colab->-r requirements.txt (line 38))\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting python-multipart (from carvekit-colab->-r requirements.txt (line 38))\n",
            "  Downloading python_multipart-0.0.19-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 39))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning->-r requirements.txt (line 40))\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->-r requirements.txt (line 40))\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia->-r requirements.txt (line 42))\n",
            "  Downloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting ftfy (from clip==1.0->-r requirements.txt (line 43))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 46)) (4.12.3)\n",
            "Collecting pybind11 (from cubvh==0.1.0->-r requirements.txt (line 53))\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 58)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 58)) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 58)) (4.3.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 58)) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 58)) (1.3.4)\n",
            "Collecting fire (from shap-e==0.0.0->-r requirements.txt (line 62))\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from shap-e==0.0.0->-r requirements.txt (line 62)) (4.11.0)\n",
            "Collecting blobfile (from shap-e==0.0.0->-r requirements.txt (line 62))\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 65)) (0.27.2)\n",
            "Collecting ipykernel>=6.5.0 (from jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 65)) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 65)) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 65)) (0.2.4)\n",
            "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 65)) (2.1.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 65)) (6.3.3)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 65)) (5.7.1)\n",
            "Requirement already satisfied: debugpy in /usr/local/lib/python3.10/dist-packages (from debugpy-run->-r requirements.txt (line 68)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from ipdb->-r requirements.txt (line 79)) (7.34.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipdb->-r requirements.txt (line 79)) (4.4.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 40)) (3.11.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 58)) (4.0.11)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->-r requirements.txt (line 65)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->-r requirements.txt (line 65)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->-r requirements.txt (line 65)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->-r requirements.txt (line 65)) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->-r requirements.txt (line 65)) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->-r requirements.txt (line 65)) (0.14.0)\n",
            "Collecting comm>=0.1.1 (from ipykernel>=6.5.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->-r requirements.txt (line 65)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->-r requirements.txt (line 65)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->-r requirements.txt (line 65)) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->-r requirements.txt (line 65)) (24.0.1)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb->-r requirements.txt (line 79))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 79)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 79)) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 79)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 79)) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.3->jupyterlab->-r requirements.txt (line 65)) (3.0.2)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (23.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (7.16.4)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (0.21.0)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (1.8.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r requirements.txt (line 65)) (2.16.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg->-r requirements.txt (line 36)) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg->-r requirements.txt (line 36)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg->-r requirements.txt (line 36)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg->-r requirements.txt (line 36)) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.2->-r requirements.txt (line 26)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.2->-r requirements.txt (line 26)) (2.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.6.7->-r requirements.txt (line 56)) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.6.7->-r requirements.txt (line 56)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.4->timm==0.6.7->-r requirements.txt (line 56)) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 46)) (2.6)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile->shap-e==0.0.0->-r requirements.txt (line 62))\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->shap-e==0.0.0->-r requirements.txt (line 62)) (5.3.0)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi->carvekit-colab->-r requirements.txt (line 38))\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->carvekit-colab->-r requirements.txt (line 38)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->carvekit-colab->-r requirements.txt (line 38)) (2.23.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0->-r requirements.txt (line 43)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->diffusers==0.20.2->-r requirements.txt (line 26)) (3.21.0)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.10/dist-packages (from pymatting->rembg->-r requirements.txt (line 36)) (0.60.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 46)) (1.7.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg->-r requirements.txt (line 36)) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg->-r requirements.txt (line 36)) (0.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 40)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 40)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 40)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 40)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 40)) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 40)) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 40)) (4.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->-r requirements.txt (line 65)) (1.2.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (21.2.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 58)) (5.0.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb->-r requirements.txt (line 79)) (0.8.4)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (2.20.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba!=0.49.0->pymatting->rembg->-r requirements.txt (line 36)) (0.43.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb->-r requirements.txt (line 79)) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (0.5.1)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (24.11.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65)) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 65))\n",
            "  Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl.metadata (1.9 kB)\n",
            "Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_ema-0.3-py3-none-any.whl (5.5 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dearpygui-2.0.0-cp310-cp310-manylinux1_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xatlas-0.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.1/230.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMCubes-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rembg-2.0.60-py3-none-any.whl (39 kB)\n",
            "Downloading carvekit_colab-4.1.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading taming_transformers_rom1504-0.0.6-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.4/899.4 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trimesh-4.5.3-py3-none-any.whl (704 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.8/704.8 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymeshlab-2023.12.post2-cp310-cp310-manylinux_2_31_x86_64.whl (98.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/98.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.3.1-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading debugpy_run-1.12-py3-none-any.whl (7.0 kB)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMatting-1.1.13-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.19-py3-none-any.whl (24 kB)\n",
            "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)\n",
            "Building wheels for collected packages: diffusers, nvdiffrast, antlr4-python3-runtime, clip, cubvh, shap-e, fire\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.20.2-py3-none-any.whl size=1342662 sha256=fc1eaf4f6311efd14f762fefa8ab4efbeb4d4f0320417b94b43c316cd48c9057\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/8b/d9/34f7a1936109e05e9bba0cc2241a6f8cd89e25959dc7aae942\n",
            "  Building wheel for nvdiffrast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvdiffrast: filename=nvdiffrast-0.3.3-py3-none-any.whl size=139907 sha256=6d54a65899e97dd2a80ce5c6234482071cf0f4b0626c5aafe115030ab33f4445\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z5i16rxy/wheels/4f/a3/e6/b3dbfa8dd5aebc3efe7b2ecb646ad1037fb3ab27ef7d6e6d02\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=13ebaca76991912581006e8b9c402e067d8ebe41c8c5a0cddeb52bfeaa8a7f8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=98062684ed069510f2954dab35dcb98f7f3395a844e2012c582c731e7a07caca\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z5i16rxy/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "  Building wheel for cubvh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cubvh: filename=cubvh-0.1.0-cp310-cp310-linux_x86_64.whl size=3358478 sha256=67df02c5643ebd0c8f859e59be908a1a41f814345b2f3f13ac5dd5ea68e5b5e0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z5i16rxy/wheels/c8/ba/f3/4c716cd8897e589fedae29a3b6f5daeb2e5295ffe0490a616c\n",
            "  Building wheel for shap-e (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap-e: filename=shap_e-0.0.0-py3-none-any.whl size=133336 sha256=1748c5b28f89f3d153eef43c563deeda59efec8f30d7de6860f80d327d3c722a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z5i16rxy/wheels/96/f3/d6/1a80c0f15cfbd33dba80d2a19c8370ba7d6e23f676847d51f2\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=27c103698f7ce4f59a073f4fa92db727fd4163ba61fa10b6b3ceff70367e912a\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built diffusers nvdiffrast antlr4-python3-runtime clip cubvh shap-e fire\n",
            "Installing collected packages: antlr4-python3-runtime, xatlas, uvicorn, uri-template, types-python-dateutil, trimesh, tensorboardX, rfc3986-validator, rfc3339-validator, python-multipart, python-json-logger, pymeshlab, pycryptodomex, pybind11, overrides, omegaconf, nvdiffrast, ninja, loguru, lightning-utilities, kornia-rs, json5, jedi, ftfy, fqdn, fire, debugpy-run, dearpygui, comm, async-lru, aiofiles, starlette, PyMCubes, pymatting, jupyter-server-terminals, jupyter-client, blobfile, arrow, torchmetrics, torch-ema, pytorch_msssim, kornia, isoduration, ipykernel, ipdb, fastapi, diffusers, cubvh, timm, rembg, lpips, clip, carvekit-colab, shap-e, pytorch-lightning, jupyter-events, taming-transformers-rom1504, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.31.0\n",
            "    Uninstalling diffusers-0.31.0:\n",
            "      Successfully uninstalled diffusers-0.31.0\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.11\n",
            "    Uninstalling timm-1.0.11:\n",
            "      Successfully uninstalled timm-1.0.11\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\n",
            "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMCubes-0.1.6 aiofiles-24.1.0 antlr4-python3-runtime-4.9.3 arrow-1.3.0 async-lru-2.0.4 blobfile-3.0.0 carvekit-colab-4.1.2 clip-1.0 comm-0.2.2 cubvh-0.1.0 dearpygui-2.0.0 debugpy-run-1.12 diffusers-0.20.2 fastapi-0.115.5 fire-0.7.0 fqdn-1.5.1 ftfy-6.3.1 ipdb-0.13.13 ipykernel-6.29.5 isoduration-20.11.0 jedi-0.19.2 json5-0.10.0 jupyter-client-8.6.3 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.3.1 jupyterlab-server-2.27.3 kornia-0.7.4 kornia-rs-0.1.7 lightning-utilities-0.11.9 loguru-0.7.2 lpips-0.1.4 ninja-1.11.1.2 nvdiffrast-0.3.3 omegaconf-2.3.0 overrides-7.7.0 pybind11-2.13.6 pycryptodomex-3.21.0 pymatting-1.1.13 pymeshlab-2023.12.post2 python-json-logger-2.0.7 python-multipart-0.0.19 pytorch-lightning-2.4.0 pytorch_msssim-1.0.0 rembg-2.0.60 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 shap-e-0.0.0 starlette-0.41.3 taming-transformers-rom1504-0.0.6 tensorboardX-2.6.2.2 timm-0.6.7 torch-ema-0.3 torchmetrics-1.6.0 trimesh-4.5.3 types-python-dateutil-2.9.0.20241003 uri-template-1.3.0 uvicorn-0.32.1 xatlas-0.0.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "8e58fb81428a4e14809778ab52ef0e08"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jaxtyping libigl envlight controlnet-aux diffusers==0.21.4 nerfacc huggingface_hub==0.25.2"
      ],
      "metadata": {
        "id": "QSMbR9dB_J9o",
        "outputId": "a08af488-9a2f-4bd2-8c52-c78d851478d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.2.36-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting libigl\n",
            "  Downloading libigl-2.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting envlight\n",
            "  Downloading envlight-0.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting controlnet-aux\n",
            "  Downloading controlnet_aux-0.0.9-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting diffusers==0.21.4\n",
            "  Downloading diffusers-0.21.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nerfacc\n",
            "  Downloading nerfacc-0.5.3-py3-none-any.whl.metadata (915 bytes)\n",
            "Collecting huggingface_hub==0.25.2\n",
            "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (3.16.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (8.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (0.4.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.25.2) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.25.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.25.2) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.25.2) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.25.2) (4.12.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from libigl) (1.13.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from envlight) (1.11.1.2)\n",
            "Requirement already satisfied: imageio>=2.28.0 in /usr/local/lib/python3.10/dist-packages (from envlight) (2.36.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from controlnet-aux) (2.5.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from controlnet-aux) (4.10.0.84)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from controlnet-aux) (0.8.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from controlnet-aux) (0.20.1+cu121)\n",
            "Requirement already satisfied: timm<=0.6.7 in /usr/local/lib/python3.10/dist-packages (from controlnet-aux) (0.6.7)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from controlnet-aux) (0.24.0)\n",
            "Requirement already satisfied: rich>=12 in /usr/local/lib/python3.10/dist-packages (from nerfacc) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12->nerfacc) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12->nerfacc) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->controlnet-aux) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->controlnet-aux) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->controlnet-aux) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->controlnet-aux) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.21.4) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.4) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.4) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.4) (2024.8.30)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->controlnet-aux) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->controlnet-aux) (0.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12->nerfacc) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->controlnet-aux) (3.0.2)\n",
            "Downloading diffusers-0.21.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.2.36-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libigl-2.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading envlight-0.1.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading controlnet_aux-0.0.9-py3-none-any.whl (282 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.4/282.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nerfacc-0.5.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jaxtyping, libigl, huggingface_hub, envlight, nerfacc, diffusers, controlnet-aux\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.26.2\n",
            "    Uninstalling huggingface-hub-0.26.2:\n",
            "      Successfully uninstalled huggingface-hub-0.26.2\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.20.2\n",
            "    Uninstalling diffusers-0.20.2:\n",
            "      Successfully uninstalled diffusers-0.20.2\n",
            "Successfully installed controlnet-aux-0.0.9 diffusers-0.21.4 envlight-0.1.0 huggingface_hub-0.25.2 jaxtyping-0.2.36 libigl-2.5.1 nerfacc-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this process will take quite long\n",
        "!pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch"
      ],
      "metadata": {
        "id": "f7dnA8pP_n7Y",
        "outputId": "07725b2e-b1f5-42cf-b3c3-30ec240a21be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch\n",
            "  Cloning https://github.com/NVlabs/tiny-cuda-nn/ to /tmp/pip-req-build-ie8l67o2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NVlabs/tiny-cuda-nn/ /tmp/pip-req-build-ie8l67o2\n",
            "  Resolved https://github.com/NVlabs/tiny-cuda-nn/ to commit c91138bcd4c6877c8d5e60e483c0581aafc70cce\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tinycudann\n",
            "  Building wheel for tinycudann (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinycudann: filename=tinycudann-1.7-cp310-cp310-linux_x86_64.whl size=30081800 sha256=892e268608e5770cc8f974686486543da037a27db3f6a4e28f5f7291f2c704ce\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0ikpgfln/wheels/32/d8/5e/dc94eca0794af9e09a6d97f19cf15dfe9bbbc4d56ae4db4aa2\n",
            "Successfully built tinycudann\n",
            "Installing collected packages: tinycudann\n",
            "Successfully installed tinycudann-1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Image Preprocessing & Textual Inversion\n"
      ],
      "metadata": {
        "id": "oR4MYqQ5NOcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd threestudio/custom/MVP124"
      ],
      "metadata": {
        "id": "88zhtI_RPdod",
        "outputId": "698c3324-0ae2-4568-e0e3-c6e83912b4b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/threestudio/custom/MVP124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install backgroundremover"
      ],
      "metadata": {
        "id": "qbih3i0cQDtX",
        "outputId": "a805b17c-9752-4c06-a812-6a7fc8e327cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting backgroundremover\n",
            "  Downloading backgroundremover-0.2.8.tar.gz (19 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi>=2021.5.30 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (2024.8.30)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (3.4.0)\n",
            "Requirement already satisfied: filelock>=3.0.12 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (3.16.1)\n",
            "Requirement already satisfied: idna>=3.2 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (3.10)\n",
            "Requirement already satisfied: PySocks>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (1.7.1)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (1.26.4)\n",
            "Requirement already satisfied: scikit-image>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (0.24.0)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (0.20.1+cu121)\n",
            "Collecting waitress>=1.4.4 (from backgroundremover)\n",
            "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tqdm>=4.51.0 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (4.66.6)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (1.13.1)\n",
            "Requirement already satisfied: pymatting>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (1.1.13)\n",
            "Collecting filetype>=1.0.7 (from backgroundremover)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting hsh>=1.1.0 (from backgroundremover)\n",
            "  Downloading hsh-1.1.0-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: more_itertools>=8.7.0 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (10.5.0)\n",
            "Requirement already satisfied: moviepy>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from backgroundremover) (1.0.3)\n",
            "Collecting Pillow<10.0.0,>=8.1.1 (from backgroundremover)\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting ffmpeg-python (from backgroundremover)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting commandlines (from hsh>=1.1.0->backgroundremover)\n",
            "  Downloading commandlines-0.4.1-py2.py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.3->backgroundremover) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.3->backgroundremover) (2.36.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.3->backgroundremover) (0.5.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.3->backgroundremover) (0.1.10)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.10/dist-packages (from pymatting>=1.1.1->backgroundremover) (0.60.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17.2->backgroundremover) (3.4.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17.2->backgroundremover) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17.2->backgroundremover) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17.2->backgroundremover) (0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->backgroundremover) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->backgroundremover) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->backgroundremover) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->backgroundremover) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.0->backgroundremover) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python->backgroundremover) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy>=1.0.3->backgroundremover) (75.1.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba!=0.49.0->pymatting>=1.1.1->backgroundremover) (0.43.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->backgroundremover) (3.0.2)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading hsh-1.1.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading commandlines-0.4.1-py2.py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: backgroundremover\n",
            "  Building wheel for backgroundremover (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for backgroundremover: filename=backgroundremover-0.2.8-py3-none-any.whl size=19420 sha256=6fc1b8153c6efd50fcb298a904ff05e8a481637a3d788284f53fbb7c65dab765\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/de/f1/21a553e1ea663c4a3372919b8fd88cb9899dd4cbcd3140baf3\n",
            "Successfully built backgroundremover\n",
            "Installing collected packages: filetype, commandlines, waitress, Pillow, hsh, ffmpeg-python, backgroundremover\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "Successfully installed Pillow-9.5.0 backgroundremover-0.2.8 commandlines-0.4.1 ffmpeg-python-0.2.0 filetype-1.2.0 hsh-1.1.0 waitress-3.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "d1d1528b597e419a8c8236d3dbbee534"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload personalized image\n",
        "!python image_preprocess.py \"load/christmas-deer/image.jpg\" --size 512 --border_ratio 0.0"
      ],
      "metadata": {
        "id": "iSL1WlFT-fLQ",
        "outputId": "b919eb9e-ad79-4f65-b744-3cd461bdd270",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading image...\n",
            "[INFO] background removal...\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "load/christmas-deer/_rgba.png\n",
            "DEBUG: path to be checked: /root/.u2net/u2net.pth\n",
            "downloading model [u2net] to /root/.u2net/u2net.pth ...\n",
            "downloading part 1 of u2net\n",
            "finished downloading part 1 of u2net\n",
            "downloading part 2 of u2net\n",
            "finished downloading part 2 of u2net\n",
            "downloading part 3 of u2net\n",
            "finished downloading part 3 of u2net\n",
            "downloading part 4 of u2net\n",
            "finished downloading part 4 of u2net\n",
            "[INFO] depth estimation...\n",
            "omnidata_dpt_depth_v2.ckpt: 100% 1.95G/1.95G [00:13<00:00, 149MB/s]\n",
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_resnet50_384-9fd3c705.pth\" to /root/.cache/torch/hub/checkpoints/jx_vit_base_resnet50_384-9fd3c705.pth\n",
            "/content/threestudio/custom/MVP124/image_preprocess.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(path, map_location=\"cpu\")\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "[INFO] normal estimation...\n",
            "omnidata_dpt_normal_v2.ckpt: 100% 1.95G/1.95G [00:12<00:00, 158MB/s] \n",
            "/content/threestudio/custom/MVP124/image_preprocess.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(path, map_location=\"cpu\")\n",
            "[INFO] recenter...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../.."
      ],
      "metadata": {
        "id": "ioEy3TEQ_4ht",
        "outputId": "73947f8d-ea14-4de4-ac75-ddc9dad5e0e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/threestudio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers"
      ],
      "metadata": {
        "id": "0ano0ymvAUMs",
        "outputId": "e667cfd4-12e8-4d0e-c382-7f5a459d6b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xformers\n",
            "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->xformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->xformers) (3.0.2)\n",
            "Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xformers\n",
            "Successfully installed xformers-0.0.28.post3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install av"
      ],
      "metadata": {
        "id": "ON6dg0ANiwRU",
        "outputId": "7d89824e-1aa7-45be-9398-a774a51dd5b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting av\n",
            "  Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-13.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Textual Inversion\n",
        "gpu=0\n",
        "CUSTOM_DIR=\"custom/MVP124\"\n",
        "MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\n",
        "DATA_DIR=f\"{CUSTOM_DIR}/load/simba-lion/image.jpg\" # \"path-to-dir-containing-your-image\"\n",
        "OUTPUT_DIR=\"outputs-textual-run/simba-lion\" # \"path-to-desired-output-dir\"\n",
        "placeholder_token=\"_simba-lion_\"\n",
        "init_token=\"_simba-lion_\"\n",
        "!echo \"Placeholder Token $placeholder_token\"\n",
        "\n",
        "CUDA_VISIBLE_DEVICES={gpu}\n",
        "!accelerate launch {CUSTOM_DIR}/textual-inversion/textual_inversion.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --train_data_dir=$DATA_DIR \\\n",
        "  --learnable_property=\"object\" \\\n",
        "  --placeholder_token=$placeholder_token \\\n",
        "  --initializer_token=$init_token \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=16 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --max_train_steps=3000 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --use_augmentations \\\n",
        "  --only_save_embeds \\\n",
        "  --validation_prompt \"A high-resolution image of simba-lion\" \\\n",
        "  --enable_xformers_memory_efficient_attention \\\n",
        "  --mixed_precision=\"fp16\""
      ],
      "metadata": {
        "id": "VLAusl4yUJyj",
        "outputId": "cffb5c87-c484-4d38-f40f-e4036386e457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Placeholder Token _simba-lion_\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-11-27 19:28:44.211323: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-27 19:28:44.227929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-27 19:28:44.247133: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-27 19:28:44.253015: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-27 19:28:44.267493: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-27 19:28:45.443956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "A matching Triton is not available, some optimizations will not be enabled\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xformers/__init__.py\", line 57, in _is_triton_available\n",
            "    import triton  # noqa\n",
            "ModuleNotFoundError: No module named 'triton'\n",
            "11/27/2024 19:28:47 - INFO - __main__ - Namespace(save_steps=500, only_save_embeds=True, pretrained_model_name_or_path='runwayml/stable-diffusion-v1-5', revision=None, tokenizer_name=None, train_data_dir='custom/MVP124/load/simba-lion/image.jpg', placeholder_token='_simba-lion_', initializer_token='_simba-lion_', learnable_property='object', repeats=100, output_dir='outputs-textual-run/simba-lion', seed=None, resolution=512, center_crop=False, train_batch_size=16, num_train_epochs=100, max_train_steps=3000, gradient_accumulation_steps=1, gradient_checkpointing=False, learning_rate=0.0001, scale_lr=False, lr_scheduler='constant', lr_warmup_steps=0, dataloader_num_workers=0, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, push_to_hub=False, hub_token=None, hub_model_id=None, logging_dir='logs', mixed_precision='fp16', allow_tf32=False, report_to='tensorboard', validation_prompt='A high-resolution image of simba-lion', num_validation_images=4, validation_steps=100, validation_epochs=None, local_rank=-1, checkpointing_steps=500, checkpoints_total_limit=None, resume_from_checkpoint=None, enable_xformers_memory_efficient_attention=True, use_augmentations=True)\n",
            "11/27/2024 19:28:47 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'clip_sample_range', 'timestep_spacing', 'dynamic_thresholding_ratio', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "{'only_cross_attention', 'timestep_post_act', 'class_embed_type', 'resnet_skip_time_act', 'class_embeddings_concat', 'attention_type', 'use_linear_projection', 'time_embedding_dim', 'num_class_embeds', 'addition_embed_type', 'resnet_time_scale_shift', 'upcast_attention', 'dropout', 'transformer_layers_per_block', 'mid_block_only_cross_attention', 'time_cond_proj_dim', 'dual_cross_attention', 'encoder_hid_dim', 'time_embedding_type', 'time_embedding_act_fn', 'num_attention_heads', 'resnet_out_scale_factor', 'addition_time_embed_dim', 'conv_in_kernel', 'mid_block_type', 'encoder_hid_dim_type', 'cross_attention_norm', 'addition_embed_type_num_heads', 'conv_out_kernel', 'projection_class_embeddings_input_dim'} was not found in config. Values will be initialized to default values.\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "11/27/2024 19:28:52 - INFO - __main__ - ***** Running training *****\n",
            "11/27/2024 19:28:52 - INFO - __main__ -   Num examples = 100\n",
            "11/27/2024 19:28:52 - INFO - __main__ -   Num Epochs = 429\n",
            "11/27/2024 19:28:52 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "11/27/2024 19:28:52 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "11/27/2024 19:28:52 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "11/27/2024 19:28:52 - INFO - __main__ -   Total optimization steps = 3000\n",
            "Steps:   3% 100/3000 [02:02<1:03:00,  1.30s/it, loss=0.0882, lr=0.0001]11/27/2024 19:30:54 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "\n",
            "model_index.json: 100% 541/541 [00:00<00:00, 3.91MB/s]\n",
            "\n",
            "Fetching 5 files:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "safety_checker/config.json: 100% 4.72k/4.72k [00:00<00:00, 25.0MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/1.22G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)ature_extractor/preprocessor_config.json: 100% 342/342 [00:00<00:00, 2.26MB/s]\n",
            "\n",
            "Fetching 5 files:  20% 1/5 [00:00<00:01,  3.66it/s]\u001b[A\n",
            "\n",
            "model.safetensors:   1% 10.5M/1.22G [00:00<00:13, 91.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   3% 41.9M/1.22G [00:00<00:06, 184MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   6% 73.4M/1.22G [00:00<00:05, 213MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   9% 105M/1.22G [00:00<00:05, 222MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  11% 136M/1.22G [00:00<00:04, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  14% 168M/1.22G [00:00<00:04, 223MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  16% 199M/1.22G [00:00<00:04, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  19% 231M/1.22G [00:01<00:04, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  22% 262M/1.22G [00:01<00:04, 227MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  24% 294M/1.22G [00:01<00:03, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  27% 325M/1.22G [00:01<00:03, 234MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  29% 357M/1.22G [00:01<00:03, 233MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  32% 388M/1.22G [00:01<00:03, 233MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  34% 419M/1.22G [00:01<00:03, 234MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  37% 451M/1.22G [00:01<00:03, 234MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  40% 482M/1.22G [00:02<00:03, 235MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  42% 514M/1.22G [00:02<00:03, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  45% 545M/1.22G [00:02<00:02, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  47% 577M/1.22G [00:02<00:02, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  50% 608M/1.22G [00:02<00:02, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  53% 640M/1.22G [00:02<00:02, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  55% 671M/1.22G [00:02<00:02, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  58% 703M/1.22G [00:03<00:02, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  60% 734M/1.22G [00:03<00:02, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  63% 765M/1.22G [00:03<00:01, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  66% 797M/1.22G [00:03<00:01, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  68% 828M/1.22G [00:03<00:01, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  71% 860M/1.22G [00:03<00:01, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  73% 891M/1.22G [00:03<00:01, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  76% 923M/1.22G [00:04<00:01, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  78% 954M/1.22G [00:04<00:01, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  81% 986M/1.22G [00:04<00:01, 227MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  84% 1.02G/1.22G [00:04<00:00, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  86% 1.05G/1.22G [00:04<00:00, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  89% 1.08G/1.22G [00:04<00:00, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  91% 1.11G/1.22G [00:04<00:00, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  94% 1.14G/1.22G [00:05<00:00, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  97% 1.17G/1.22G [00:05<00:00, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors: 100% 1.22G/1.22G [00:05<00:00, 226MB/s]\n",
            "\n",
            "Fetching 5 files: 100% 5/5 [00:05<00:00,  1.12s/it]\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:05,  1.05it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  7.20it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:   7% 200/3000 [04:12<56:37,  1.21s/it, loss=0.0713, lr=0.0001]11/27/2024 19:33:04 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.26it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  8.75it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  10% 300/3000 [06:14<49:07,  1.09s/it, loss=0.0796, lr=0.0001]11/27/2024 19:35:06 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.40it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.75it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  13% 400/3000 [08:17<50:28,  1.16s/it, loss=0.088, lr=0.0001]11/27/2024 19:37:09 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.36it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.51it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  17% 500/3000 [10:20<49:33,  1.19s/it, loss=0.0468, lr=0.0001]11/27/2024 19:39:12 - INFO - __main__ - Saving embeddings\n",
            "11/27/2024 19:39:12 - INFO - accelerate.accelerator - Saving current state to outputs-textual-run/simba-lion/checkpoint-500\n",
            "11/27/2024 19:39:13 - INFO - accelerate.checkpointing - Model weights saved in outputs-textual-run/simba-lion/checkpoint-500/model.safetensors\n",
            "11/27/2024 19:39:13 - INFO - accelerate.checkpointing - Optimizer state saved in outputs-textual-run/simba-lion/checkpoint-500/optimizer.bin\n",
            "11/27/2024 19:39:13 - INFO - accelerate.checkpointing - Scheduler state saved in outputs-textual-run/simba-lion/checkpoint-500/scheduler.bin\n",
            "11/27/2024 19:39:13 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in outputs-textual-run/simba-lion/checkpoint-500/sampler.bin\n",
            "11/27/2024 19:39:13 - INFO - accelerate.checkpointing - Gradient scaler state saved in outputs-textual-run/simba-lion/checkpoint-500/scaler.pt\n",
            "11/27/2024 19:39:13 - INFO - accelerate.checkpointing - Random states saved in outputs-textual-run/simba-lion/checkpoint-500/random_states_0.pkl\n",
            "11/27/2024 19:39:13 - INFO - __main__ - Saved state to outputs-textual-run/simba-lion/checkpoint-500\n",
            "11/27/2024 19:39:13 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.39it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.68it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  20% 600/3000 [12:25<50:55,  1.27s/it, loss=0.103, lr=0.0001]11/27/2024 19:41:17 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.38it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.64it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  23% 700/3000 [14:25<31:16,  1.23it/s, loss=0.0677, lr=0.0001]11/27/2024 19:43:17 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.45it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00, 10.08it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  27% 800/3000 [16:28<44:00,  1.20s/it, loss=0.0628, lr=0.0001]11/27/2024 19:45:20 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.40it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.78it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  30% 900/3000 [18:30<42:10,  1.21s/it, loss=0.085, lr=0.0001]11/27/2024 19:47:22 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.37it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.54it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  33% 1000/3000 [20:31<35:49,  1.07s/it, loss=0.123, lr=0.0001]11/27/2024 19:49:23 - INFO - __main__ - Saving embeddings\n",
            "11/27/2024 19:49:23 - INFO - accelerate.accelerator - Saving current state to outputs-textual-run/simba-lion/checkpoint-1000\n",
            "11/27/2024 19:49:24 - INFO - accelerate.checkpointing - Model weights saved in outputs-textual-run/simba-lion/checkpoint-1000/model.safetensors\n",
            "11/27/2024 19:49:24 - INFO - accelerate.checkpointing - Optimizer state saved in outputs-textual-run/simba-lion/checkpoint-1000/optimizer.bin\n",
            "11/27/2024 19:49:24 - INFO - accelerate.checkpointing - Scheduler state saved in outputs-textual-run/simba-lion/checkpoint-1000/scheduler.bin\n",
            "11/27/2024 19:49:24 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in outputs-textual-run/simba-lion/checkpoint-1000/sampler.bin\n",
            "11/27/2024 19:49:24 - INFO - accelerate.checkpointing - Gradient scaler state saved in outputs-textual-run/simba-lion/checkpoint-1000/scaler.pt\n",
            "11/27/2024 19:49:24 - INFO - accelerate.checkpointing - Random states saved in outputs-textual-run/simba-lion/checkpoint-1000/random_states_0.pkl\n",
            "11/27/2024 19:49:24 - INFO - __main__ - Saved state to outputs-textual-run/simba-lion/checkpoint-1000\n",
            "11/27/2024 19:49:24 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.43it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.95it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  37% 1100/3000 [22:35<36:27,  1.15s/it, loss=0.101, lr=0.0001]11/27/2024 19:51:27 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.39it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.72it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  40% 1200/3000 [24:36<37:06,  1.24s/it, loss=0.0591, lr=0.0001]11/27/2024 19:53:29 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.39it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.70it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  43% 1300/3000 [26:39<35:24,  1.25s/it, loss=0.0563, lr=0.0001]11/27/2024 19:55:31 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.39it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.72it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  47% 1400/3000 [28:39<21:22,  1.25it/s, loss=0.062, lr=0.0001]11/27/2024 19:57:31 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.45it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00, 10.12it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  50% 1500/3000 [30:42<30:03,  1.20s/it, loss=0.0681, lr=0.0001]11/27/2024 19:59:34 - INFO - __main__ - Saving embeddings\n",
            "11/27/2024 19:59:34 - INFO - accelerate.accelerator - Saving current state to outputs-textual-run/simba-lion/checkpoint-1500\n",
            "11/27/2024 19:59:35 - INFO - accelerate.checkpointing - Model weights saved in outputs-textual-run/simba-lion/checkpoint-1500/model.safetensors\n",
            "11/27/2024 19:59:35 - INFO - accelerate.checkpointing - Optimizer state saved in outputs-textual-run/simba-lion/checkpoint-1500/optimizer.bin\n",
            "11/27/2024 19:59:35 - INFO - accelerate.checkpointing - Scheduler state saved in outputs-textual-run/simba-lion/checkpoint-1500/scheduler.bin\n",
            "11/27/2024 19:59:35 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in outputs-textual-run/simba-lion/checkpoint-1500/sampler.bin\n",
            "11/27/2024 19:59:35 - INFO - accelerate.checkpointing - Gradient scaler state saved in outputs-textual-run/simba-lion/checkpoint-1500/scaler.pt\n",
            "11/27/2024 19:59:35 - INFO - accelerate.checkpointing - Random states saved in outputs-textual-run/simba-lion/checkpoint-1500/random_states_0.pkl\n",
            "11/27/2024 19:59:35 - INFO - __main__ - Saved state to outputs-textual-run/simba-lion/checkpoint-1500\n",
            "11/27/2024 19:59:35 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.40it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.78it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  53% 1600/3000 [32:47<28:55,  1.24s/it, loss=0.0867, lr=0.0001]11/27/2024 20:01:39 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.38it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.59it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  57% 1700/3000 [34:50<23:45,  1.10s/it, loss=0.0798, lr=0.0001]11/27/2024 20:03:42 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.42it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.90it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  60% 1800/3000 [36:52<23:15,  1.16s/it, loss=0.0299, lr=0.0001]11/27/2024 20:05:44 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.37it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.56it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  63% 1900/3000 [38:55<21:54,  1.19s/it, loss=0.0682, lr=0.0001]11/27/2024 20:07:47 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.41it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.83it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  67% 2000/3000 [40:58<21:03,  1.26s/it, loss=0.0812, lr=0.0001]11/27/2024 20:09:50 - INFO - __main__ - Saving embeddings\n",
            "11/27/2024 20:09:50 - INFO - accelerate.accelerator - Saving current state to outputs-textual-run/simba-lion/checkpoint-2000\n",
            "11/27/2024 20:09:51 - INFO - accelerate.checkpointing - Model weights saved in outputs-textual-run/simba-lion/checkpoint-2000/model.safetensors\n",
            "11/27/2024 20:09:52 - INFO - accelerate.checkpointing - Optimizer state saved in outputs-textual-run/simba-lion/checkpoint-2000/optimizer.bin\n",
            "11/27/2024 20:09:52 - INFO - accelerate.checkpointing - Scheduler state saved in outputs-textual-run/simba-lion/checkpoint-2000/scheduler.bin\n",
            "11/27/2024 20:09:52 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in outputs-textual-run/simba-lion/checkpoint-2000/sampler.bin\n",
            "11/27/2024 20:09:52 - INFO - accelerate.checkpointing - Gradient scaler state saved in outputs-textual-run/simba-lion/checkpoint-2000/scaler.pt\n",
            "11/27/2024 20:09:52 - INFO - accelerate.checkpointing - Random states saved in outputs-textual-run/simba-lion/checkpoint-2000/random_states_0.pkl\n",
            "11/27/2024 20:09:52 - INFO - __main__ - Saved state to outputs-textual-run/simba-lion/checkpoint-2000\n",
            "11/27/2024 20:09:52 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.36it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.51it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  70% 2100/3000 [42:59<12:04,  1.24it/s, loss=0.0336, lr=0.0001]11/27/2024 20:11:52 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.43it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.93it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  73% 2200/3000 [45:03<15:53,  1.19s/it, loss=0.0713, lr=0.0001]11/27/2024 20:13:55 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.38it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.61it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  77% 2300/3000 [47:06<14:37,  1.25s/it, loss=0.108, lr=0.0001]11/27/2024 20:15:58 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.38it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.63it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  80% 2400/3000 [49:08<11:08,  1.11s/it, loss=0.0674, lr=0.0001]11/27/2024 20:18:00 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.42it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.88it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  83% 2500/3000 [51:10<09:59,  1.20s/it, loss=0.0914, lr=0.0001]11/27/2024 20:20:03 - INFO - __main__ - Saving embeddings\n",
            "11/27/2024 20:20:03 - INFO - accelerate.accelerator - Saving current state to outputs-textual-run/simba-lion/checkpoint-2500\n",
            "11/27/2024 20:20:03 - INFO - accelerate.checkpointing - Model weights saved in outputs-textual-run/simba-lion/checkpoint-2500/model.safetensors\n",
            "11/27/2024 20:20:04 - INFO - accelerate.checkpointing - Optimizer state saved in outputs-textual-run/simba-lion/checkpoint-2500/optimizer.bin\n",
            "11/27/2024 20:20:04 - INFO - accelerate.checkpointing - Scheduler state saved in outputs-textual-run/simba-lion/checkpoint-2500/scheduler.bin\n",
            "11/27/2024 20:20:04 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in outputs-textual-run/simba-lion/checkpoint-2500/sampler.bin\n",
            "11/27/2024 20:20:04 - INFO - accelerate.checkpointing - Gradient scaler state saved in outputs-textual-run/simba-lion/checkpoint-2500/scaler.pt\n",
            "11/27/2024 20:20:04 - INFO - accelerate.checkpointing - Random states saved in outputs-textual-run/simba-lion/checkpoint-2500/random_states_0.pkl\n",
            "11/27/2024 20:20:04 - INFO - __main__ - Saved state to outputs-textual-run/simba-lion/checkpoint-2500\n",
            "11/27/2024 20:20:04 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.39it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.70it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  87% 2600/3000 [53:14<08:18,  1.25s/it, loss=0.0669, lr=0.0001]11/27/2024 20:22:06 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.41it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.81it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  90% 2700/3000 [55:16<06:24,  1.28s/it, loss=0.0543, lr=0.0001]11/27/2024 20:24:08 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.40it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.77it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  93% 2800/3000 [57:16<02:40,  1.24it/s, loss=0.062, lr=0.0001]11/27/2024 20:26:09 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.42it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.87it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  97% 2900/3000 [59:21<02:05,  1.26s/it, loss=0.0639, lr=0.0001]11/27/2024 20:28:13 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.37it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.58it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps: 100% 3000/3000 [1:01:24<00:00,  1.25s/it, loss=0.0802, lr=0.0001]11/27/2024 20:30:16 - INFO - __main__ - Saving embeddings\n",
            "11/27/2024 20:30:16 - INFO - accelerate.accelerator - Saving current state to outputs-textual-run/simba-lion/checkpoint-3000\n",
            "11/27/2024 20:30:17 - INFO - accelerate.checkpointing - Model weights saved in outputs-textual-run/simba-lion/checkpoint-3000/model.safetensors\n",
            "11/27/2024 20:30:18 - INFO - accelerate.checkpointing - Optimizer state saved in outputs-textual-run/simba-lion/checkpoint-3000/optimizer.bin\n",
            "11/27/2024 20:30:18 - INFO - accelerate.checkpointing - Scheduler state saved in outputs-textual-run/simba-lion/checkpoint-3000/scheduler.bin\n",
            "11/27/2024 20:30:18 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in outputs-textual-run/simba-lion/checkpoint-3000/sampler.bin\n",
            "11/27/2024 20:30:18 - INFO - accelerate.checkpointing - Gradient scaler state saved in outputs-textual-run/simba-lion/checkpoint-3000/scaler.pt\n",
            "11/27/2024 20:30:18 - INFO - accelerate.checkpointing - Random states saved in outputs-textual-run/simba-lion/checkpoint-3000/random_states_0.pkl\n",
            "11/27/2024 20:30:18 - INFO - __main__ - Saved state to outputs-textual-run/simba-lion/checkpoint-3000\n",
            "11/27/2024 20:30:18 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A high-resolution image of simba-lion.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:04,  1.38it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.65it/s]\n",
            "{'thresholding', 'prediction_type', 'sample_max_value', 'lower_order_final', 'solver_type', 'algorithm_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'solver_order', 'use_karras_sigmas', 'lambda_min_clipped', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps: 100% 3000/3000 [1:01:33<00:00,  1.25s/it, loss=0.106, lr=0.0001] 11/27/2024 20:30:25 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 3000/3000 [1:01:33<00:00,  1.23s/it, loss=0.106, lr=0.0001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training (Stage 1)"
      ],
      "metadata": {
        "id": "Yc1TqP-1NoHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install av"
      ],
      "metadata": {
        "id": "6Tif3KCF0IXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed=0\n",
        "gpu=0\n",
        "exp_root_dir=\"outputs\"\n",
        "DATA_DIR=\"space-shuttle\"\n",
        "STATIC_PROMPT=\"a high resolution DSLR image of space shuttle\"\n",
        "DYNAMIC_PROMPT=\"a space shuttle is launching\"\n",
        "CN_PROMPT=\"a <token> is launching\"\n",
        "\n",
        "# --------- Stage 1 (Static Stage) --------- #\n",
        "!python launch.py --config custom/MVP124/configs/animate124-stage1.yaml --train --gpu $gpu \\\n",
        "data.image.image_path=custom/MVP124/load/space-shuttle/_rgba.png \\\n",
        "system.prompt_processor.prompt=\"${STATIC_PROMPT}\""
      ],
      "metadata": {
        "id": "v-QRWEOwU0hm",
        "outputId": "5363fea0-da1a-4b31-e499-aa785c10aa2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/threestudio/threestudio/utils/ops.py:45: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=torch.float32)\n",
            "/content/threestudio/threestudio/utils/ops.py:52: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, g):  # pylint: disable=arguments-differ\n",
            "/content/threestudio/threestudio/utils/ops.py:62: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input_tensor, gt_grad):\n",
            "/content/threestudio/threestudio/utils/ops.py:69: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_scale):\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
            "  warnings.warn(\n",
            "2024-12-01 19:01:39.769942: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-01 19:01:39.785929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 19:01:39.806123: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 19:01:39.812542: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 19:01:39.828175: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 19:01:41.004488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "A matching Triton is not available, some optimizations will not be enabled\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xformers/__init__.py\", line 57, in _is_triton_available\n",
            "    import triton  # noqa\n",
            "ModuleNotFoundError: No module named 'triton'\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:185: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:195: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:207: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:107: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:335: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:115: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:134: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:156: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:146: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:170: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:480: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:533: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:153: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:172: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:182: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:560: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:283: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:326: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:748: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:222: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:252: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:402: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:421: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:431: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:146: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:180: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:191: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:201: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:172: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:183: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:194: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:204: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:350: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_unified_guidance.py:287: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_unified_guidance.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_unified_guidance.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:163: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:168: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:183: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:201: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:221: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:231: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:243: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/zeroscope_guidance.py:163: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/zeroscope_guidance.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/zeroscope_guidance.py:244: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "\n",
            "Import times for custom modules:\n",
            "   0.1 seconds: custom/MVP124\n",
            "\n",
            "Seed set to 0\n",
            "\u001b[32m[INFO] Loading Stable Diffusion ...\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "model_index.json: 100% 541/541 [00:00<00:00, 3.52MB/s]\n",
            "Fetching 8 files:   0% 0/8 [00:00<?, ?it/s]\n",
            "diffusion_pytorch_model.safetensors:   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   6% 21.0M/335M [00:00<00:01, 198MB/s]\u001b[A\n",
            "\n",
            "scheduler/scheduler_config.json: 100% 308/308 [00:00<00:00, 2.14MB/s]\n",
            "Fetching 8 files:  25% 2/8 [00:00<00:02,  2.91it/s]\n",
            "\n",
            "vae/config.json: 100% 547/547 [00:00<00:00, 4.52MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/492M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   0% 0.00/3.44G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "unet/config.json: 100% 743/743 [00:00<00:00, 6.53MB/s]\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  16% 52.4M/335M [00:00<00:01, 235MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "text_encoder/config.json: 100% 617/617 [00:00<00:00, 5.52MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   4% 21.0M/492M [00:00<00:02, 198MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   1% 31.5M/3.44G [00:00<00:14, 232MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  25% 83.9M/335M [00:00<00:01, 236MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  11% 52.4M/492M [00:00<00:01, 246MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   2% 62.9M/3.44G [00:00<00:13, 246MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  34% 115M/335M [00:00<00:00, 245MB/s] \u001b[A\n",
            "\n",
            "model.safetensors:  17% 83.9M/492M [00:00<00:01, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   3% 94.4M/3.44G [00:00<00:13, 248MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  44% 147M/335M [00:00<00:00, 248MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  23% 115M/492M [00:00<00:01, 244MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   4% 126M/3.44G [00:00<00:13, 251MB/s] \u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  53% 178M/335M [00:00<00:00, 250MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  30% 147M/492M [00:00<00:01, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   5% 157M/3.44G [00:00<00:13, 252MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  36% 178M/492M [00:00<00:01, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   5% 189M/3.44G [00:00<00:13, 248MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  63% 210M/335M [00:00<00:00, 186MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  43% 210M/492M [00:00<00:01, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   6% 220M/3.44G [00:00<00:12, 249MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  72% 241M/335M [00:01<00:00, 200MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  49% 241M/492M [00:00<00:01, 250MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   7% 252M/3.44G [00:01<00:12, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  81% 273M/335M [00:01<00:00, 214MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  55% 273M/492M [00:01<00:00, 250MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   8% 283M/3.44G [00:01<00:12, 249MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  91% 304M/335M [00:01<00:00, 225MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  62% 304M/492M [00:01<00:00, 245MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 234MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 224MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:  68% 336M/492M [00:01<00:00, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  10% 346M/3.44G [00:01<00:12, 252MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  75% 367M/492M [00:01<00:00, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  11% 377M/3.44G [00:01<00:12, 252MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  81% 398M/492M [00:01<00:00, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  12% 409M/3.44G [00:01<00:12, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  87% 430M/492M [00:01<00:00, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  13% 440M/3.44G [00:01<00:14, 207MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  94% 461M/492M [00:01<00:00, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  14% 472M/3.44G [00:01<00:13, 217MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors: 100% 492M/492M [00:02<00:00, 237MB/s]\n",
            "Fetching 8 files:  50% 4/8 [00:02<00:03,  1.31it/s]\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  15% 503M/3.44G [00:02<00:12, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  16% 535M/3.44G [00:02<00:12, 236MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  16% 566M/3.44G [00:02<00:11, 241MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  17% 598M/3.44G [00:02<00:11, 245MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  18% 629M/3.44G [00:02<00:15, 177MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  19% 661M/3.44G [00:02<00:14, 196MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  20% 692M/3.44G [00:03<00:13, 211MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  21% 724M/3.44G [00:03<00:12, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  22% 755M/3.44G [00:03<00:11, 233MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  23% 786M/3.44G [00:03<00:11, 239MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  24% 818M/3.44G [00:03<00:10, 244MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  25% 849M/3.44G [00:03<00:15, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  26% 881M/3.44G [00:03<00:13, 190MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  27% 912M/3.44G [00:04<00:12, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  27% 944M/3.44G [00:04<00:11, 219MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  28% 975M/3.44G [00:04<00:10, 229MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  29% 1.01G/3.44G [00:04<00:10, 236MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  30% 1.04G/3.44G [00:04<00:09, 240MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  31% 1.07G/3.44G [00:04<00:13, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  32% 1.10G/3.44G [00:04<00:12, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  33% 1.13G/3.44G [00:05<00:11, 205MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  34% 1.16G/3.44G [00:05<00:10, 216MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  35% 1.20G/3.44G [00:05<00:09, 229MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  36% 1.23G/3.44G [00:05<00:09, 232MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  37% 1.26G/3.44G [00:05<00:12, 174MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  38% 1.29G/3.44G [00:05<00:11, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  38% 1.32G/3.44G [00:06<00:10, 207MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  39% 1.35G/3.44G [00:06<00:09, 220MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  40% 1.38G/3.44G [00:06<00:08, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  41% 1.42G/3.44G [00:06<00:08, 236MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  42% 1.45G/3.44G [00:06<00:08, 240MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  43% 1.48G/3.44G [00:06<00:11, 174MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  44% 1.51G/3.44G [00:06<00:10, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  45% 1.54G/3.44G [00:07<00:09, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  46% 1.57G/3.44G [00:07<00:08, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  47% 1.60G/3.44G [00:07<00:08, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  48% 1.64G/3.44G [00:07<00:07, 232MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  48% 1.67G/3.44G [00:07<00:07, 237MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  49% 1.70G/3.44G [00:07<00:09, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  50% 1.73G/3.44G [00:07<00:08, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  51% 1.76G/3.44G [00:08<00:08, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  52% 1.79G/3.44G [00:08<00:07, 220MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  53% 1.82G/3.44G [00:08<00:07, 227MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  54% 1.86G/3.44G [00:08<00:06, 234MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  55% 1.89G/3.44G [00:08<00:08, 174MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  56% 1.92G/3.44G [00:08<00:07, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  57% 1.95G/3.44G [00:09<00:07, 207MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  58% 1.98G/3.44G [00:09<00:06, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  59% 2.01G/3.44G [00:09<00:06, 227MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  59% 2.04G/3.44G [00:09<00:06, 232MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  60% 2.08G/3.44G [00:09<00:05, 238MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  61% 2.11G/3.44G [00:09<00:07, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  62% 2.14G/3.44G [00:09<00:06, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  63% 2.17G/3.44G [00:10<00:06, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  64% 2.20G/3.44G [00:10<00:05, 219MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  65% 2.23G/3.44G [00:10<00:05, 227MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  66% 2.26G/3.44G [00:10<00:04, 237MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  67% 2.30G/3.44G [00:10<00:04, 253MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  68% 2.33G/3.44G [00:10<00:06, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  69% 2.36G/3.44G [00:10<00:05, 189MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  70% 2.39G/3.44G [00:11<00:05, 202MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  70% 2.42G/3.44G [00:11<00:04, 217MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  71% 2.45G/3.44G [00:11<00:04, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  72% 2.49G/3.44G [00:11<00:04, 234MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  73% 2.52G/3.44G [00:11<00:05, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  74% 2.55G/3.44G [00:11<00:04, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  75% 2.58G/3.44G [00:12<00:04, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  76% 2.61G/3.44G [00:12<00:03, 219MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  77% 2.64G/3.44G [00:12<00:03, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  78% 2.67G/3.44G [00:12<00:03, 233MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  79% 2.71G/3.44G [00:12<00:03, 238MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  80% 2.74G/3.44G [00:12<00:03, 177MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  81% 2.77G/3.44G [00:12<00:03, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  81% 2.80G/3.44G [00:13<00:03, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  82% 2.83G/3.44G [00:13<00:02, 219MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  83% 2.86G/3.44G [00:13<00:02, 229MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  84% 2.89G/3.44G [00:13<00:02, 235MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  85% 2.93G/3.44G [00:13<00:02, 239MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  86% 2.96G/3.44G [00:13<00:02, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  87% 2.99G/3.44G [00:13<00:02, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  88% 3.02G/3.44G [00:14<00:02, 207MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  89% 3.05G/3.44G [00:14<00:01, 217MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  90% 3.08G/3.44G [00:14<00:01, 225MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  91% 3.11G/3.44G [00:14<00:01, 231MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  91% 3.15G/3.44G [00:14<00:01, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  92% 3.18G/3.44G [00:14<00:01, 194MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  93% 3.21G/3.44G [00:15<00:01, 205MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  94% 3.24G/3.44G [00:15<00:00, 213MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  95% 3.27G/3.44G [00:15<00:00, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  96% 3.30G/3.44G [00:15<00:00, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  97% 3.33G/3.44G [00:15<00:00, 234MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  98% 3.37G/3.44G [00:15<00:00, 179MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  99% 3.40G/3.44G [00:15<00:00, 200MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors: 100% 3.44G/3.44G [00:16<00:00, 214MB/s]\n",
            "Fetching 8 files: 100% 8/8 [00:16<00:00,  2.10s/it]\n",
            "Loading pipeline components...: 100% 4/4 [00:01<00:00,  2.23it/s]\n",
            "\u001b[32m[INFO] Loaded Stable Diffusion!\u001b[0m\n",
            "\u001b[32m[INFO] Using prompt [high resolution DSLR image of space shuttle] and negative prompt []\u001b[0m\n",
            "\u001b[32m[INFO] Using view-dependent prompts [side]:[high resolution DSLR image of space shuttle, side view] [front]:[high resolution DSLR image of space shuttle, front view] [back]:[high resolution DSLR image of space shuttle, back view] [overhead]:[high resolution DSLR image of space shuttle, overhead view]\u001b[0m\n",
            "tokenizer/tokenizer_config.json: 100% 806/806 [00:00<00:00, 5.04MB/s]\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 34.9MB/s]\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 74.0MB/s]\n",
            "tokenizer/special_tokens_map.json: 100% 472/472 [00:00<00:00, 3.29MB/s]\n",
            "/content/threestudio/threestudio/models/prompt_processors/base.py:420: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(cache_path, map_location=self.device)\n",
            "\u001b[32m[INFO] Loading Zero123 ...\u001b[0m\n",
            "model_index.json: 100% 562/562 [00:00<00:00, 2.90MB/s]\n",
            "Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\n",
            "image_encoder/config.json: 100% 585/585 [00:00<00:00, 3.32MB/s]\n",
            "\n",
            "(…)ature_extractor/preprocessor_config.json: 100% 518/518 [00:00<00:00, 3.83MB/s]\n",
            "\n",
            "unet/config.json: 100% 1.68k/1.68k [00:00<00:00, 16.4MB/s]\n",
            "\n",
            "scheduler/scheduler_config.json: 100% 502/502 [00:00<00:00, 4.08MB/s]\n",
            "\n",
            "model.fp16.safetensors:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   0% 0.00/1.19M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "clip_camera_projection/config.json: 100% 132/132 [00:00<00:00, 1.10MB/s]\n",
            "Fetching 11 files:   9% 1/11 [00:00<00:05,  1.89it/s]\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors: 100% 1.19M/1.19M [00:00<00:00, 63.6MB/s]\n",
            "\n",
            "\n",
            "vae/config.json: 100% 577/577 [00:00<00:00, 3.17MB/s]\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   1% 10.5M/1.72G [00:00<01:10, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   1% 21.0M/1.72G [00:00<01:09, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   6% 10.5M/167M [00:00<00:09, 16.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   2% 31.5M/1.72G [00:01<01:07, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:   2% 10.5M/608M [00:01<01:25, 7.02MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  13% 21.0M/167M [00:01<00:07, 20.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   2% 41.9M/1.72G [00:01<01:07, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  19% 31.5M/167M [00:01<00:05, 22.8MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:   3% 21.0M/608M [00:01<00:48, 12.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   3% 52.4M/1.72G [00:02<01:07, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  25% 41.9M/167M [00:01<00:05, 23.9MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:   5% 31.5M/608M [00:02<00:36, 15.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   4% 62.9M/1.72G [00:02<01:06, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  31% 52.4M/167M [00:02<00:04, 24.4MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:   7% 41.9M/608M [00:02<00:30, 18.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   4% 73.4M/1.72G [00:02<01:06, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  38% 62.9M/167M [00:02<00:04, 24.8MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:   9% 52.4M/608M [00:03<00:27, 20.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   5% 83.9M/1.72G [00:03<01:05, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  44% 73.4M/167M [00:03<00:03, 25.0MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  10% 62.9M/608M [00:03<00:25, 21.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   5% 94.4M/1.72G [00:03<01:05, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  50% 83.9M/167M [00:03<00:03, 25.2MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  12% 73.4M/608M [00:04<00:23, 22.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   6% 105M/1.72G [00:04<01:05, 24.8MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  56% 94.4M/167M [00:03<00:02, 25.2MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  14% 83.9M/608M [00:04<00:22, 23.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   7% 115M/1.72G [00:04<01:04, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  63% 105M/167M [00:04<00:02, 25.3MB/s] \u001b[A\u001b[A\n",
            "model.fp16.safetensors:  16% 94.4M/608M [00:04<00:21, 23.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   7% 126M/1.72G [00:05<01:04, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  69% 115M/167M [00:04<00:02, 25.3MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  17% 105M/608M [00:05<00:20, 24.0MB/s] \u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   8% 136M/1.72G [00:05<01:03, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  75% 126M/167M [00:05<00:01, 24.8MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  19% 115M/608M [00:05<00:20, 24.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   9% 147M/1.72G [00:05<01:03, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  81% 136M/167M [00:05<00:01, 25.6MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  21% 126M/608M [00:06<00:19, 24.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   9% 157M/1.72G [00:06<01:03, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  88% 147M/167M [00:05<00:00, 25.5MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  22% 136M/608M [00:06<00:19, 24.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  10% 168M/1.72G [00:06<01:02, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  94% 157M/167M [00:06<00:00, 25.5MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  24% 147M/608M [00:06<00:18, 24.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  10% 178M/1.72G [00:07<01:02, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors: 100% 167M/167M [00:06<00:00, 24.6MB/s]\n",
            "\n",
            "model.fp16.safetensors:  26% 157M/608M [00:07<00:18, 24.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  11% 189M/1.72G [00:07<01:01, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  28% 168M/608M [00:07<00:18, 24.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  12% 199M/1.72G [00:08<01:01, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  29% 178M/608M [00:08<00:17, 24.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  12% 210M/1.72G [00:08<01:00, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  31% 189M/608M [00:08<00:17, 24.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  13% 220M/1.72G [00:08<01:00, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  33% 199M/608M [00:09<00:16, 24.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  13% 231M/1.72G [00:09<01:00, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  34% 210M/608M [00:09<00:16, 24.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  14% 241M/1.72G [00:09<00:59, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  36% 220M/608M [00:10<00:17, 22.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  15% 252M/1.72G [00:10<00:59, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  38% 231M/608M [00:10<00:16, 23.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  15% 262M/1.72G [00:10<00:58, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  40% 241M/608M [00:10<00:15, 23.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  16% 273M/1.72G [00:11<00:58, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  41% 252M/608M [00:11<00:14, 24.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  16% 283M/1.72G [00:11<00:58, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  43% 262M/608M [00:11<00:14, 24.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  17% 294M/1.72G [00:11<00:57, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  45% 273M/608M [00:12<00:13, 24.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  18% 304M/1.72G [00:12<00:57, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  47% 283M/608M [00:12<00:13, 24.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  18% 315M/1.72G [00:12<00:56, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  48% 294M/608M [00:13<00:12, 24.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  19% 325M/1.72G [00:13<00:56, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  50% 304M/608M [00:13<00:12, 24.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  20% 336M/1.72G [00:13<00:55, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  52% 315M/608M [00:13<00:11, 24.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  20% 346M/1.72G [00:13<00:55, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  53% 325M/608M [00:14<00:11, 24.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  21% 357M/1.72G [00:14<00:55, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  55% 336M/608M [00:14<00:11, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  21% 367M/1.72G [00:14<00:54, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  57% 346M/608M [00:15<00:10, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  22% 377M/1.72G [00:15<00:54, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  59% 357M/608M [00:15<00:10, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  23% 388M/1.72G [00:15<00:53, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  60% 367M/608M [00:16<00:09, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  23% 398M/1.72G [00:16<00:53, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  62% 377M/608M [00:16<00:09, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  24% 409M/1.72G [00:16<00:53, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  64% 388M/608M [00:16<00:08, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  24% 419M/1.72G [00:16<00:52, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  66% 398M/608M [00:17<00:08, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  25% 430M/1.72G [00:17<00:52, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  67% 409M/608M [00:17<00:08, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  26% 440M/1.72G [00:17<00:51, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  69% 419M/608M [00:18<00:07, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  26% 451M/1.72G [00:18<00:51, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  71% 430M/608M [00:18<00:07, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  27% 461M/1.72G [00:18<00:50, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  72% 440M/608M [00:18<00:06, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  27% 472M/1.72G [00:19<00:50, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  74% 451M/608M [00:19<00:06, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  28% 482M/1.72G [00:19<00:50, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  76% 461M/608M [00:19<00:05, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  29% 493M/1.72G [00:19<00:49, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  78% 472M/608M [00:20<00:05, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  29% 503M/1.72G [00:20<00:49, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  79% 482M/608M [00:20<00:05, 24.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  30% 514M/1.72G [00:20<00:48, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  81% 493M/608M [00:21<00:04, 25.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  30% 524M/1.72G [00:21<00:48, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  83% 503M/608M [00:21<00:04, 25.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  31% 535M/1.72G [00:21<00:48, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  85% 514M/608M [00:21<00:03, 24.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  32% 545M/1.72G [00:22<00:47, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  86% 524M/608M [00:22<00:03, 24.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  32% 556M/1.72G [00:22<00:47, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  88% 535M/608M [00:22<00:02, 24.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  33% 566M/1.72G [00:22<00:46, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  90% 545M/608M [00:23<00:02, 24.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  34% 577M/1.72G [00:23<00:46, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  91% 556M/608M [00:23<00:02, 24.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  34% 587M/1.72G [00:23<00:45, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  93% 566M/608M [00:24<00:01, 24.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  35% 598M/1.72G [00:24<00:45, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  95% 577M/608M [00:24<00:01, 24.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  35% 608M/1.72G [00:24<00:45, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  97% 587M/608M [00:24<00:00, 24.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  36% 619M/1.72G [00:25<00:44, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  98% 598M/608M [00:25<00:00, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  37% 629M/1.72G [00:25<00:44, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors: 100% 608M/608M [00:25<00:00, 23.6MB/s]\n",
            "Fetching 11 files:  45% 5/11 [00:26<00:33,  5.57s/it]\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  37% 640M/1.72G [00:25<00:43, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  38% 650M/1.72G [00:26<00:43, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  38% 661M/1.72G [00:26<00:42, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  39% 671M/1.72G [00:27<00:43, 24.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  40% 682M/1.72G [00:27<00:43, 23.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  40% 692M/1.72G [00:28<00:42, 23.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  41% 703M/1.72G [00:28<00:42, 24.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  41% 713M/1.72G [00:28<00:41, 24.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  42% 724M/1.72G [00:29<00:41, 24.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  43% 734M/1.72G [00:29<00:40, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  43% 744M/1.72G [00:30<00:40, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  44% 755M/1.72G [00:30<00:39, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  45% 765M/1.72G [00:31<00:39, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  45% 776M/1.72G [00:31<00:38, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  46% 786M/1.72G [00:31<00:38, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  46% 797M/1.72G [00:32<00:37, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  47% 807M/1.72G [00:32<00:37, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  48% 818M/1.72G [00:33<00:36, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  48% 828M/1.72G [00:33<00:36, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  49% 839M/1.72G [00:34<00:35, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  49% 849M/1.72G [00:34<00:35, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  50% 860M/1.72G [00:34<00:34, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  51% 870M/1.72G [00:35<00:34, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  51% 881M/1.72G [00:35<00:33, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  52% 891M/1.72G [00:36<00:33, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  52% 902M/1.72G [00:36<00:33, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  53% 912M/1.72G [00:37<00:32, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  54% 923M/1.72G [00:37<00:32, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  54% 933M/1.72G [00:37<00:31, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  55% 944M/1.72G [00:38<00:31, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  56% 954M/1.72G [00:38<00:30, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  56% 965M/1.72G [00:39<00:30, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  57% 975M/1.72G [00:39<00:30, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  57% 986M/1.72G [00:40<00:29, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  58% 996M/1.72G [00:40<00:29, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  59% 1.01G/1.72G [00:40<00:28, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  59% 1.02G/1.72G [00:41<00:28, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  60% 1.03G/1.72G [00:41<00:28, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  60% 1.04G/1.72G [00:42<00:27, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  61% 1.05G/1.72G [00:42<00:27, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  62% 1.06G/1.72G [00:42<00:26, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  62% 1.07G/1.72G [00:43<00:26, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  63% 1.08G/1.72G [00:43<00:25, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  63% 1.09G/1.72G [00:44<00:25, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  64% 1.10G/1.72G [00:44<00:25, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  65% 1.11G/1.72G [00:45<00:24, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  65% 1.12G/1.72G [00:45<00:25, 23.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  66% 1.13G/1.72G [00:46<00:24, 23.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  66% 1.14G/1.72G [00:46<00:23, 24.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  67% 1.15G/1.72G [00:46<00:23, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  68% 1.16G/1.72G [00:47<00:22, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  68% 1.17G/1.72G [00:47<00:22, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  69% 1.18G/1.72G [00:48<00:21, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  70% 1.20G/1.72G [00:48<00:21, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  70% 1.21G/1.72G [00:49<00:20, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  71% 1.22G/1.72G [00:49<00:20, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  71% 1.23G/1.72G [00:49<00:19, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  72% 1.24G/1.72G [00:50<00:19, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  73% 1.25G/1.72G [00:50<00:19, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  73% 1.26G/1.72G [00:51<00:18, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  74% 1.27G/1.72G [00:51<00:18, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  74% 1.28G/1.72G [00:51<00:17, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  75% 1.29G/1.72G [00:52<00:17, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  76% 1.30G/1.72G [00:52<00:16, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  76% 1.31G/1.72G [00:53<00:16, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  77% 1.32G/1.72G [00:53<00:16, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  77% 1.33G/1.72G [00:54<00:15, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  78% 1.34G/1.72G [00:54<00:15, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  79% 1.35G/1.72G [00:54<00:15, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  79% 1.36G/1.72G [00:55<00:14, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  80% 1.37G/1.72G [00:55<00:14, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  81% 1.38G/1.72G [00:56<00:13, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  81% 1.39G/1.72G [00:56<00:13, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  82% 1.41G/1.72G [00:57<00:12, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  82% 1.42G/1.72G [00:57<00:12, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  83% 1.43G/1.72G [00:57<00:11, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  84% 1.44G/1.72G [00:58<00:11, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  84% 1.45G/1.72G [00:58<00:11, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  85% 1.46G/1.72G [00:59<00:10, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  85% 1.47G/1.72G [00:59<00:10, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  86% 1.48G/1.72G [01:00<00:09, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  87% 1.49G/1.72G [01:00<00:09, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  87% 1.50G/1.72G [01:00<00:08, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  88% 1.51G/1.72G [01:01<00:08, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  88% 1.52G/1.72G [01:01<00:08, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  89% 1.53G/1.72G [01:02<00:07, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  90% 1.54G/1.72G [01:02<00:07, 23.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  90% 1.55G/1.72G [01:03<00:06, 24.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  91% 1.56G/1.72G [01:03<00:06, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  91% 1.57G/1.72G [01:03<00:05, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  92% 1.58G/1.72G [01:04<00:05, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  93% 1.59G/1.72G [01:04<00:05, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  93% 1.60G/1.72G [01:05<00:04, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  94% 1.61G/1.72G [01:05<00:04, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  95% 1.63G/1.72G [01:06<00:03, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  95% 1.64G/1.72G [01:06<00:03, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  96% 1.65G/1.72G [01:06<00:03, 24.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  96% 1.66G/1.72G [01:07<00:02, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  97% 1.67G/1.72G [01:07<00:02, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  98% 1.68G/1.72G [01:08<00:01, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  98% 1.69G/1.72G [01:08<00:01, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  99% 1.70G/1.72G [01:09<00:00, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  99% 1.71G/1.72G [01:09<00:00, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors: 100% 1.72G/1.72G [01:09<00:00, 24.6MB/s]\n",
            "Fetching 11 files: 100% 11/11 [01:10<00:00,  6.41s/it]\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  7.98it/s]\n",
            "\u001b[32m[INFO] Loaded Stable Diffusion!\u001b[0m\n",
            "\u001b[32m[INFO] Using 16bit Automatic Mixed Precision (AMP)\u001b[0m\n",
            "\u001b[32m[INFO] GPU available: True (cuda), used: True\u001b[0m\n",
            "\u001b[32m[INFO] TPU available: False, using: 0 TPU cores\u001b[0m\n",
            "\u001b[32m[INFO] HPU available: False, using: 0 HPUs\u001b[0m\n",
            "\u001b[32m[INFO] You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\u001b[0m\n",
            "/content/threestudio/threestudio/data/image.py:93: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
            "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
            "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:62.)\n",
            "  right: Float[Tensor, \"1 3\"] = F.normalize(torch.cross(lookat, up), dim=-1)\n",
            "[INFO] single image dataset: load image custom/MVP124/load/space-shuttle/_rgba.png torch.Size([1, 128, 128, 3])\n",
            "\u001b[32m[INFO] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
            "\u001b[32m[INFO] \n",
            "  | Name              | Type                           | Params | Mode \n",
            "-----------------------------------------------------------------------------\n",
            "0 | geometry          | ImplicitVolume                 | 28.1 M | train\n",
            "1 | material          | NoMaterial                     | 0      | train\n",
            "2 | background        | SolidColorBackground           | 0      | train\n",
            "3 | renderer          | NeRFVolumeRenderer             | 0      | train\n",
            "4 | geometry_encoding | TCNNEncodingSpatialTime        | 28.1 M | train\n",
            "5 | guidance_video    | StableDiffusionUnifiedGuidance | 0      | train\n",
            "6 | guidance_3d       | Zero123UnifiedGuidance         | 0      | train\n",
            "-----------------------------------------------------------------------------\n",
            "12.6 M    Trainable params\n",
            "15.5 M    Non-trainable params\n",
            "28.1 M    Total params\n",
            "112.316   Total estimated model params size (MB)\n",
            "21        Modules in train mode\n",
            "0         Modules in eval mode\u001b[0m\n",
            "\u001b[32m[INFO] Validation results will be saved to outputs/animate124-stage1/high_resolution_DSLR_image_of_space_shuttle@20241201-190144/save\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "Epoch 0: |          | 0/? [00:00<?, ?it/s] /content/threestudio/custom/MVP124/models/networks.py:254: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "\u001b[?25l/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: \n",
            "TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "\u001b[2K\u001b[32m(●     )\u001b[0m \u001b[1;33mNerfAcc: Setting up CUDA (This may take a few minutes the first time)\u001b[0m\n",
            "\u001b[1A\u001b[2K/content/threestudio/custom/MVP124/models/networks.py:254: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/content/threestudio/custom/MVP124/systems/animate124.py:228: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "Epoch 0: |          | 1000/? [06:00<00:00,  2.78it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:00<00:00, 26.46it/s]\u001b[A\n",
            "Epoch 0: |          | 2000/? [10:22<00:00,  3.21it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:00<00:00, 35.19it/s]\u001b[A\n",
            "Epoch 0: |          | 3000/? [14:40<00:00,  3.41it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:00<00:00, 38.10it/s]\u001b[A\n",
            "Epoch 0: |          | 4000/? [18:56<00:00,  3.52it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:00<00:00, 38.41it/s]\u001b[A\n",
            "Epoch 0: |          | 5000/? [23:12<00:00,  3.59it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:00<00:00, 37.59it/s]\u001b[A\n",
            "Epoch 0: |          | 6000/? [27:27<00:00,  3.64it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:00<00:00, 37.82it/s]\u001b[A\n",
            "Epoch 0: |          | 7000/? [31:43<00:00,  3.68it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:00<00:00, 40.15it/s]\u001b[A\n",
            "Epoch 0: |          | 8000/? [36:00<00:00,  3.70it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:00<00:00, 38.04it/s]\u001b[A\n",
            "Epoch 0: |          | 9000/? [40:16<00:00,  3.72it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:00<00:00, 39.82it/s]\u001b[A\n",
            "Epoch 0: |          | 10000/? [44:32<00:00,  3.74it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:00<00:00, 36.72it/s]\u001b[A\n",
            "Epoch 0: |          | 10000/? [44:33<00:00,  3.74it/s]\u001b[32m[INFO] `Trainer.fit` stopped: `max_steps=10000` reached.\u001b[0m\n",
            "Epoch 0: |          | 10000/? [44:33<00:00,  3.74it/s]\n",
            "\u001b[32m[INFO] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "Testing DataLoader 0: 100% 120/120 [00:02<00:00, 42.86it/s]/usr/local/lib/python3.10/dist-packages/torchvision/io/video.py:91: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  video_array = torch.as_tensor(video_array, dtype=torch.uint8).numpy(force=True)\n",
            "Testing DataLoader 0: 100% 120/120 [00:28<00:00,  4.26it/s]\n",
            "\u001b[32m[INFO] Test results saved to outputs/animate124-stage1/high_resolution_DSLR_image_of_space_shuttle@20241201-190144/save\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r outputs.zip \"outputs/animate124-stage1/high_resolution_DSLR_image_of_space_shuttle@20241201-190144/save\""
      ],
      "metadata": {
        "id": "njviLHRzi0Fe",
        "outputId": "c350c5da-33d9-46ae-af22-12022ac36520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: outputs/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-2.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it5000-2.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it2000-0.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-0.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it2000-3.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it8000-2.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it6000-1.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it8000-1.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it4000-3.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it3000-2.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it8000-3.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it1000-3.png (deflated 2%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-3.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it3000-0.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it7000-2.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it9000-0.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it7000-1.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/7.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/76.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/85.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/68.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/40.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/109.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/37.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/44.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/31.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/119.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/102.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/57.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/64.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/86.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/52.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/65.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/63.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/51.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/62.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/12.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/24.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/67.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/118.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/30.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/39.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/55.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/115.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/72.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/107.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/113.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/81.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/16.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/61.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/104.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/23.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/5.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/17.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/90.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/13.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/79.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/41.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/26.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/88.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/116.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/6.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/91.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/94.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/28.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/59.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/42.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/89.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/35.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/96.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/93.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/10.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/21.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/46.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/15.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/53.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/117.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/87.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/33.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/84.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/49.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/43.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/82.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/105.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/0.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/73.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/70.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/78.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/101.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/27.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/106.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/22.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/38.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/45.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/14.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/98.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/66.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/25.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/4.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/60.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/9.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/56.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/1.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/95.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/34.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/99.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/20.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/58.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/47.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/100.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/92.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/36.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/110.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/111.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/19.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/108.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/114.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/74.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/83.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/8.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/80.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/48.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/18.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/75.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/2.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/50.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/97.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/3.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/103.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/69.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/32.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/71.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/112.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/54.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/77.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/11.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test-normal/29.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it4000-1.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it4000-0.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it8000-0.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it1000-1.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/7.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/76.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/85.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/68.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/40.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/109.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/37.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/44.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/31.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/119.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/102.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/57.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/64.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/86.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/52.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/65.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/63.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/51.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/62.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/12.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/24.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/67.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/118.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/30.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/39.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/55.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/115.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/72.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/107.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/113.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/81.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/16.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/61.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/104.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/23.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/5.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/17.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/90.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/13.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/79.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/41.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/26.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/88.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/116.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/6.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/91.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/94.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/28.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/59.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/42.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/89.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/35.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/96.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/93.png (deflated 2%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/10.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/21.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/46.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/15.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/53.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/117.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/87.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/33.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/84.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/49.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/43.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/82.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/105.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/0.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/73.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/70.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/78.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/101.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/27.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/106.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/22.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/38.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/45.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/14.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/98.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/66.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/25.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/4.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/60.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/9.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/56.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/1.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/95.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/34.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/99.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/20.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/58.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/47.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/100.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/92.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/36.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/110.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/111.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/19.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/108.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/114.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/74.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/83.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/8.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/80.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/48.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/18.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/75.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/2.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/50.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/97.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/3.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/103.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/69.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/32.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/71.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/112.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/54.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/77.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/11.png (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-test/29.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it2000-2.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it3000-3.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it1000-0.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it4000-2.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it9000-1.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it6000-3.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it5000-3.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it7000-0.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it1000-2.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it7000-3.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it3000-1.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it10000-1.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it9000-2.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it5000-1.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it5000-0.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it6000-2.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it6000-0.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it9000-3.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/save/it2000-1.png (deflated 1%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/csv_logs/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/csv_logs/version_0/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/csv_logs/version_0/metrics.csv (deflated 76%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/csv_logs/version_0/hparams.yaml (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/ckpts/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/ckpts/last.ckpt (deflated 17%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/cmd.txt (deflated 42%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/setup.py (deflated 49%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/CHANGELOG.md (deflated 50%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/DOCUMENTATION.md (deflated 86%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/requirements.txt (deflated 39%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/.gitignore (deflated 54%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/launch.py (deflated 69%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/requirements-dev.txt (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/custom/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/custom/put_custom_extensions_here (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/2dplayground.ipynb (deflated 73%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/scripts/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/scripts/convert_zero123_to_diffusers.py (deflated 81%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/.pre-commit-config.yaml (deflated 57%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/README.md (deflated 71%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/LICENSE (deflated 65%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/threestudio.ipynb (deflated 72%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/learned_embeds-steps-2000.bin (deflated 21%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/learned_embeds.bin (deflated 19%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-1500/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-1500/optimizer.bin (deflated 100%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-1500/scheduler.bin (deflated 55%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-1500/random_states_0.pkl (deflated 25%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-1500/model.safetensors (deflated 31%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-3000/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-3000/optimizer.bin (deflated 100%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-3000/scheduler.bin (deflated 55%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-3000/random_states_0.pkl (deflated 25%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-3000/model.safetensors (deflated 31%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/learned_embeds-steps-3000.bin (deflated 21%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/1732567486.4017963/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/1732567486.4017963/hparams.yml (deflated 48%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/1732567019.5773845/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/1732567019.5773845/hparams.yml (deflated 47%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/events.out.tfevents.1732567486.b4d650659621.8100.0 (deflated 67%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/1732567019.575563/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/1732567019.575563/events.out.tfevents.1732567019.b4d650659621.5982.1 (deflated 52%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/events.out.tfevents.1732567019.b4d650659621.5982.0 (deflated 66%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/1732567486.4001343/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/logs/textual_inversion/1732567486.4001343/events.out.tfevents.1732567486.b4d650659621.8100.1 (deflated 52%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-500/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-500/optimizer.bin (deflated 100%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-500/scheduler.bin (deflated 55%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-500/random_states_0.pkl (deflated 25%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-500/model.safetensors (deflated 31%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-1300.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-1000.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-1600.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-1100.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-2300.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-2900.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-1800.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-0700.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-0600.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-1200.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-1400.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-2600.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-3000.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-0100.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-1700.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-2100.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-2400.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-2200.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-0500.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-2000.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-2700.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-1900.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-2500.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-0900.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-0300.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-0400.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-2800.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-0200.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-0800.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/validation/step-1500.jpg (deflated 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-2500/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-2500/optimizer.bin (deflated 100%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-2500/scheduler.bin (deflated 55%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-2500/random_states_0.pkl (deflated 25%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-2500/model.safetensors (deflated 31%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-2000/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-2000/optimizer.bin (deflated 100%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-2000/scheduler.bin (deflated 55%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-2000/random_states_0.pkl (deflated 25%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-2000/model.safetensors (deflated 31%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/learned_embeds-steps-2500.bin (deflated 22%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-1000/ (stored 0%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-1000/optimizer.bin (deflated 100%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-1000/scheduler.bin (deflated 55%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-1000/random_states_0.pkl (deflated 25%)\n",
            "  adding: outputs/animate124-stage1/high_resolution_DSLR_image_of_christmas_deer@20241125-220750/code/outputs-textual-run/christmas-deer/checkpoint-1000/model.safetensors\n",
            "\n",
            "\n",
            "zip error: Interrupted (aborting)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38MSAFDwjL01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training (Stage 2)"
      ],
      "metadata": {
        "id": "Bdf0cYFtNt7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !ckpt=\"outputs/animate124-stage1/${STATIC_PROMPT}@LAST/ckpts/last.ckpt\"\n",
        "!python launch.py --config custom/MVP124/configs/animate124-stage2-ms.yaml --train --gpu $gpu \\\n",
        "data.image.image_path=\"custom/MVP124/load/space-shuttle/_rgba.png\" \\\n",
        "system.prompt_processor.prompt=\"a space shuttle is launching\" \\\n",
        "system.weights=\"outputs/animate124-stage1/high_resolution_DSLR_image_of_space_shuttle@20241201-190144/ckpts/last.ckpt\""
      ],
      "metadata": {
        "id": "6bbQG84fybX7",
        "outputId": "6693104f-c142-4c94-97c5-cafec8e90662",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/threestudio/threestudio/utils/ops.py:45: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=torch.float32)\n",
            "/content/threestudio/threestudio/utils/ops.py:52: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, g):  # pylint: disable=arguments-differ\n",
            "/content/threestudio/threestudio/utils/ops.py:62: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input_tensor, gt_grad):\n",
            "/content/threestudio/threestudio/utils/ops.py:69: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_scale):\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
            "  warnings.warn(\n",
            "2024-12-01 19:59:26.109282: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-01 19:59:26.127411: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 19:59:26.149636: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 19:59:26.156258: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 19:59:26.171896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 19:59:27.354775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "A matching Triton is not available, some optimizations will not be enabled\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xformers/__init__.py\", line 57, in _is_triton_available\n",
            "    import triton  # noqa\n",
            "ModuleNotFoundError: No module named 'triton'\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:185: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:195: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:207: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:107: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:335: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:115: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:134: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:156: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:146: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:170: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:480: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:533: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:153: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:172: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:182: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:560: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:283: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:326: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:748: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:222: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:252: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:402: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:421: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:431: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:146: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:180: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:191: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:201: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:172: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:183: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:194: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:204: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:350: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_unified_guidance.py:287: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_unified_guidance.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_unified_guidance.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:163: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:168: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:183: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:201: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:221: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:231: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:243: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/zeroscope_guidance.py:163: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/zeroscope_guidance.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/zeroscope_guidance.py:244: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "\n",
            "Import times for custom modules:\n",
            "   0.0 seconds: custom/MVP124\n",
            "\n",
            "Seed set to 0\n",
            "\u001b[32m[INFO] Loading Stable Diffusion ...\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading pipeline components...: 100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "\u001b[32m[INFO] Loaded Stable Diffusion!\u001b[0m\n",
            "\u001b[32m[INFO] Using prompt [a space shuttle is launching] and negative prompt []\u001b[0m\n",
            "\u001b[32m[INFO] Using view-dependent prompts [side]:[a space shuttle is launching, side view] [front]:[a space shuttle is launching, front view] [back]:[a space shuttle is launching, back view] [overhead]:[a space shuttle is launching, overhead view]\u001b[0m\n",
            "/content/threestudio/threestudio/models/prompt_processors/base.py:420: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(cache_path, map_location=self.device)\n",
            "\u001b[32m[INFO] Loading Zero123 ...\u001b[0m\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  8.06it/s]\n",
            "\u001b[32m[INFO] Loaded Stable Diffusion!\u001b[0m\n",
            "/content/threestudio/threestudio/utils/misc.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(path, map_location=map_location)\n",
            "\u001b[32m[INFO] Using 16bit Automatic Mixed Precision (AMP)\u001b[0m\n",
            "\u001b[32m[INFO] GPU available: True (cuda), used: True\u001b[0m\n",
            "\u001b[32m[INFO] TPU available: False, using: 0 TPU cores\u001b[0m\n",
            "\u001b[32m[INFO] HPU available: False, using: 0 HPUs\u001b[0m\n",
            "\u001b[32m[INFO] You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\u001b[0m\n",
            "/content/threestudio/threestudio/data/image.py:93: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
            "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
            "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:62.)\n",
            "  right: Float[Tensor, \"1 3\"] = F.normalize(torch.cross(lookat, up), dim=-1)\n",
            "[INFO] single image dataset: load image custom/MVP124/load/space-shuttle/_rgba.png torch.Size([1, 128, 128, 3])\n",
            "\u001b[32m[INFO] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
            "\u001b[32m[INFO] \n",
            "  | Name              | Type                    | Params | Mode \n",
            "----------------------------------------------------------------------\n",
            "0 | geometry          | ImplicitVolume          | 28.1 M | train\n",
            "1 | material          | NoMaterial              | 0      | train\n",
            "2 | background        | SolidColorBackground    | 0      | train\n",
            "3 | renderer          | NeRFVolumeRenderer      | 0      | train\n",
            "4 | geometry_encoding | TCNNEncodingSpatialTime | 28.1 M | train\n",
            "5 | guidance_3d       | Zero123UnifiedGuidance  | 0      | train\n",
            "----------------------------------------------------------------------\n",
            "28.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "28.1 M    Total params\n",
            "112.316   Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\u001b[0m\n",
            "\u001b[32m[INFO] Validation results will be saved to outputs/animate124-stage2/a_space_shuttle_is_launching@20241201-195929/save\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "Epoch 0: |          | 0/? [00:00<?, ?it/s] /content/threestudio/custom/MVP124/models/networks.py:254: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "/content/threestudio/custom/MVP124/models/networks.py:254: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "Epoch 0: |          | 20/? [00:11<00:00,  1.75it/s]/content/threestudio/custom/MVP124/systems/animate124.py:228: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "Epoch 0: |          | 1000/? [09:31<00:00,  1.75it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/torchvision/io/video.py:91: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  video_array = torch.as_tensor(video_array, dtype=torch.uint8).numpy(force=True)\n",
            "\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.63s/it]\u001b[A\n",
            "Epoch 0: |          | 2000/? [19:33<00:00,  1.70it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.62s/it]\u001b[A\n",
            "Epoch 0: |          | 3000/? [29:35<00:00,  1.69it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.65s/it]\u001b[A\n",
            "Epoch 0: |          | 4000/? [39:35<00:00,  1.68it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.62s/it]\u001b[A\n",
            "Epoch 0: |          | 5000/? [49:33<00:00,  1.68it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.61s/it]\u001b[A\n",
            "Epoch 0: |          | 6000/? [59:32<00:00,  1.68it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.64s/it]\u001b[A\n",
            "Epoch 0: |          | 7000/? [1:09:31<00:00,  1.68it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.63s/it]\u001b[A\n",
            "Epoch 0: |          | 8000/? [1:19:30<00:00,  1.68it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.61s/it]\u001b[A\n",
            "Epoch 0: |          | 9000/? [1:29:24<00:00,  1.68it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.60s/it]\u001b[A\n",
            "Epoch 0: |          | 10000/? [1:39:16<00:00,  1.68it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.61s/it]\u001b[A\n",
            "Epoch 0: |          | 10000/? [1:39:48<00:00,  1.67it/s]\u001b[32m[INFO] `Trainer.fit` stopped: `max_steps=10000` reached.\u001b[0m\n",
            "Epoch 0: |          | 10000/? [1:39:48<00:00,  1.67it/s]\n",
            "\u001b[32m[INFO] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "Testing DataLoader 0: 100% 124/124 [00:43<00:00,  2.85it/s]\n",
            "\u001b[32m[INFO] Test results saved to outputs/animate124-stage2/a_space_shuttle_is_launching@20241201-195929/save\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Training (Stage 3)"
      ],
      "metadata": {
        "id": "y1agjR_uNyn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DYNAMIC_PROMPT=\"a space shuttle is launching\"\n",
        "CN_PROMPT=\"a <token> is launching\"\n",
        "\n",
        "!python launch.py --config custom/MVP124/configs/animate124-stage3-ms.yaml --train --gpu $gpu \\\n",
        "data.image.image_path=custom/MVP124/load/space-shuttle/_rgba.png \\\n",
        "system.prompt_processor.prompt=\"${DYNAMIC_PROMPT}\" \\\n",
        "system.prompt_processor_cn.prompt=\"${CN_PROMPT}\" \\\n",
        "system.prompt_processor_cn.learned_embeds_path=custom/MVP124/load/space-shuttle/learned_embeds.bin \\\n",
        "system.weights=\"outputs/animate124-stage2/a_space_shuttle_is_launching@20241201-195929/ckpts/last.ckpt\""
      ],
      "metadata": {
        "id": "0ctpg0wO1t-a",
        "outputId": "798dbba6-db72-4247-9e0e-46a748dd0887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/threestudio/threestudio/utils/ops.py:45: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=torch.float32)\n",
            "/content/threestudio/threestudio/utils/ops.py:52: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, g):  # pylint: disable=arguments-differ\n",
            "/content/threestudio/threestudio/utils/ops.py:62: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input_tensor, gt_grad):\n",
            "/content/threestudio/threestudio/utils/ops.py:69: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_scale):\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
            "  warnings.warn(\n",
            "2024-12-01 22:12:30.696108: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-01 22:12:30.713725: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 22:12:30.734506: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 22:12:30.740808: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 22:12:30.755884: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 22:12:31.902457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "A matching Triton is not available, some optimizations will not be enabled\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xformers/__init__.py\", line 57, in _is_triton_available\n",
            "    import triton  # noqa\n",
            "ModuleNotFoundError: No module named 'triton'\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:185: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:195: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/controlnet_guidance.py:207: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:107: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/deep_floyd_guidance.py:335: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:115: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:134: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/instructpix2pix_guidance.py:156: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:146: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:170: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:480: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_guidance.py:533: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:153: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:172: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:182: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_sdi_guidance.py:560: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:283: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:326: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_unified_guidance.py:748: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:222: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:252: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:402: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:421: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_diffusion_vsd_guidance.py:431: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:146: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:169: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:180: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:191: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/stable_zero123_guidance.py:201: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:172: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:183: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:194: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:204: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_guidance.py:350: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_unified_guidance.py:287: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_unified_guidance.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/threestudio/models/guidance/zero123_unified_guidance.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:163: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:168: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:183: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:201: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:221: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:231: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/controlnet_tile_guidance.py:243: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/zeroscope_guidance.py:163: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/zeroscope_guidance.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "/content/threestudio/custom/MVP124/models/guidance/zeroscope_guidance.py:244: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n",
            "\n",
            "Import times for custom modules:\n",
            "   0.0 seconds: custom/MVP124\n",
            "\n",
            "Seed set to 0\n",
            "\u001b[32m[INFO] Loading Stable Diffusion ...\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading pipeline components...: 100% 4/4 [00:01<00:00,  2.10it/s]\n",
            "\u001b[32m[INFO] Loaded Stable Diffusion!\u001b[0m\n",
            "\u001b[32m[INFO] Using prompt [space shuttle is launching] and negative prompt []\u001b[0m\n",
            "\u001b[32m[INFO] Using view-dependent prompts [side]:[space shuttle is launching, side view] [front]:[space shuttle is launching, front view] [back]:[space shuttle is launching, back view] [overhead]:[space shuttle is launching, overhead view]\u001b[0m\n",
            "/content/threestudio/threestudio/models/prompt_processors/base.py:420: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(cache_path, map_location=self.device)\n",
            "\u001b[32m[INFO] Loading Zero123 ...\u001b[0m\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  8.17it/s]\n",
            "\u001b[32m[INFO] Loaded Stable Diffusion!\u001b[0m\n",
            "\u001b[32m[INFO] Loading ControlNet ...\u001b[0m\n",
            "Loading pipeline components...: 100% 5/5 [00:01<00:00,  4.29it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/models/modeling_utils.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "\u001b[32m[INFO] Loaded ControlNet!\u001b[0m\n",
            "\u001b[32m[INFO] Using prompt [<token> is launching] and negative prompt []\u001b[0m\n",
            "\u001b[32m[INFO] Using view-dependent prompts [side]:[<token> is launching, side view] [front]:[<token> is launching, front view] [back]:[<token> is launching, back view] [overhead]:[<token> is launching, overhead view]\u001b[0m\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  5.74it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/loaders.py:719: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_file, map_location=\"cpu\")\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "/content/threestudio/custom/MVP124/models/prompt_processors/stable_diffusion_textual_inversion_prompt_processor.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  token_state_dict = torch.load(self.cfg.learned_embeds_path)\n",
            "\u001b[32m[INFO] After textual inversion token replacing: [['_shuttle_ is launching', '', '_shuttle_ is launching, side view', '_shuttle_ is launching, front view', '_shuttle_ is launching, back view', '_shuttle_ is launching, overhead view', '', '', '', '']]\u001b[0m\n",
            "/content/threestudio/threestudio/utils/misc.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(path, map_location=map_location)\n",
            "\u001b[32m[INFO] Using 16bit Automatic Mixed Precision (AMP)\u001b[0m\n",
            "\u001b[32m[INFO] GPU available: True (cuda), used: True\u001b[0m\n",
            "\u001b[32m[INFO] TPU available: False, using: 0 TPU cores\u001b[0m\n",
            "\u001b[32m[INFO] HPU available: False, using: 0 HPUs\u001b[0m\n",
            "\u001b[32m[INFO] You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\u001b[0m\n",
            "/content/threestudio/threestudio/data/image.py:93: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
            "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
            "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:62.)\n",
            "  right: Float[Tensor, \"1 3\"] = F.normalize(torch.cross(lookat, up), dim=-1)\n",
            "[INFO] single image dataset: load image custom/MVP124/load/space-shuttle/_rgba.png torch.Size([1, 128, 128, 3])\n",
            "\u001b[32m[INFO] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
            "\u001b[32m[INFO] \n",
            "  | Name              | Type                    | Params | Mode \n",
            "----------------------------------------------------------------------\n",
            "0 | geometry          | ImplicitVolume          | 28.1 M | train\n",
            "1 | material          | NoMaterial              | 0      | train\n",
            "2 | background        | SolidColorBackground    | 0      | train\n",
            "3 | renderer          | NeRFVolumeRenderer      | 0      | train\n",
            "4 | geometry_encoding | TCNNEncodingSpatialTime | 28.1 M | train\n",
            "5 | guidance_3d       | Zero123UnifiedGuidance  | 0      | train\n",
            "----------------------------------------------------------------------\n",
            "28.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "28.1 M    Total params\n",
            "112.316   Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\u001b[0m\n",
            "\u001b[32m[INFO] Validation results will be saved to outputs/animate124-stage3/space_shuttle_is_launching@20241201-221234/save\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "Epoch 0: |          | 0/? [00:00<?, ?it/s] /content/threestudio/custom/MVP124/models/networks.py:254: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "/content/threestudio/custom/MVP124/models/networks.py:254: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "Epoch 0: |          | 20/? [00:25<00:00,  0.77it/s]/content/threestudio/custom/MVP124/systems/animate124.py:228: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "Epoch 0: |          | 1000/? [21:40<00:00,  0.77it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/torchvision/io/video.py:91: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  video_array = torch.as_tensor(video_array, dtype=torch.uint8).numpy(force=True)\n",
            "\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.52s/it]\u001b[A\n",
            "Epoch 0: |          | 2000/? [43:52<00:00,  0.76it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.55s/it]\u001b[A\n",
            "Epoch 0: |          | 3000/? [1:06:03<00:00,  0.76it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.52s/it]\u001b[A\n",
            "Epoch 0: |          | 4000/? [1:28:18<00:00,  0.75it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.54s/it]\u001b[A\n",
            "Epoch 0: |          | 5000/? [1:50:34<00:00,  0.75it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/4 [00:00<?, ?it/s]        \u001b[A\n",
            "Validation DataLoader 0:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 4/4 [00:30<00:00,  7.56s/it]\u001b[A\n",
            "Epoch 0: |          | 5000/? [1:51:05<00:00,  0.75it/s]\u001b[32m[INFO] `Trainer.fit` stopped: `max_steps=5000` reached.\u001b[0m\n",
            "Epoch 0: |          | 5000/? [1:51:05<00:00,  0.75it/s]\n",
            "\u001b[32m[INFO] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "Testing DataLoader 0: 100% 124/124 [00:43<00:00,  2.88it/s]\n",
            "\u001b[32m[INFO] Test results saved to outputs/animate124-stage3/space_shuttle_is_launching@20241201-221234/save\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "b2_D_ddHtY4_",
        "outputId": "705fd756-8e57-4fbc-fc56-d53c0cc1a712",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp threestudio/outputs/animate124-stage3/space_shuttle_is_launching@20241201-221234/ckpts/last.ckpt drive/MyDrive/L344_Mini_Project"
      ],
      "metadata": {
        "id": "9KfBmUkVtp0j"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}